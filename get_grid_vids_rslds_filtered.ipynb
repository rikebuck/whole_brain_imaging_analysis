{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee9bcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worm 0, date: 2022-06-14-01\n",
      "Worm 1, date: 2023-01-23-08\n",
      "Worm 2, date: 2022-06-28-07\n",
      "Worm 3, date: 2022-07-15-12\n",
      "Worm 4, date: 2023-01-19-01\n",
      "Worm 5, date: 2022-08-02-01\n",
      "Worm 6, date: 2022-06-14-07\n",
      "Worm 7, date: 2022-06-28-01\n",
      "Worm 8, date: 2023-01-23-15\n",
      "Worm 9, date: 2022-07-26-01\n",
      "Worm 10, date: 2023-01-19-15\n",
      "Worm 11, date: 2023-03-07-01\n",
      "Worm 12, date: 2022-06-14-13\n",
      "Worm 13, date: 2023-01-23-21\n",
      "Worm 14, date: 2023-01-19-22\n",
      "Worm 15, date: 2023-01-23-01\n",
      "Worm 16, date: 2023-01-17-01\n",
      "Worm 17, date: 2022-07-20-01\n",
      "Worm 18, date: 2023-01-09-28\n",
      "Worm 19, date: 2023-01-19-08\n",
      "Worm 20, date: 2022-07-15-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/friederikebuck/Desktop/MBL/project/WholeBrainImagingAnalysis/collab/beh_classification/behavior_features.py:11: RuntimeWarning: Mean of empty slice\n",
      "  body_angles = body_angles-np.nanmean(body_angles, axis = 1)[:, None]\n",
      "/Users/friederikebuck/Desktop/MBL/project/WholeBrainImagingAnalysis/collab/beh_classification/behavior_features.py:15: RuntimeWarning: Mean of empty slice\n",
      "  centroids = np.nanmean(midlines, axis = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model with kappa=1000.0\n",
      "(21, 1599, 138)\n",
      "138\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "# %%\n",
    "import os\n",
    "# import keypoint_moseq as kpms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "sys.path.append(\"/Users/friederikebuck/Desktop/MBL/project/WholeBrainImagingAnalysis/collab/\")\n",
    "sys.path.append('/Users/bennetsakelaris/Documents/Obsidian Vault/Worms/wormcode/Code+Notes 09-24-24/collab/')\n",
    "from collections import defaultdict\n",
    "import random \n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from get_data.read_neuro_beh_data import get_exp_features, load_json\n",
    "from get_data.process_neural_data import get_derivative_of_neural_activity, get_neural_activity_from_labels, get_neural_activity_and_labels\n",
    "from beh_classification.behavior_features import get_behavior_features\n",
    "from get_data.read_neuro_beh_data import get_exp_features, load_json\n",
    "\n",
    "sys.path.append(\"/Users/friederikebuck/Desktop/MBL/project/WholeBrainImagingAnalysis/collab/\")\n",
    "sys.path.append('/Users/bennetsakelaris/Documents/Obsidian Vault/Worms/wormcode/Code+Notes 09-24-24/collab/')\n",
    "from collections import defaultdict\n",
    "import random \n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from get_data.read_neuro_beh_data import get_exp_features, load_json\n",
    "from get_data.process_neural_data import get_derivative_of_neural_activity, get_neural_activity_from_labels, get_neural_activity_and_labels\n",
    "from beh_classification.behavior_features import get_behavior_features\n",
    "from get_data.read_neuro_beh_data import get_exp_features, load_json\n",
    "import sys \n",
    "sys.path.append('/Users/friederikebuck/Desktop/MBL/project/WholeBrainImagingAnalysis/collab/')\n",
    "import sys \n",
    "sys.path.append('/Users/friederikebuck/Desktop/MBL/project/WholeBrainImagingAnalysis/collab/')\n",
    "from beh_classification.process_midlines.midline_utils import save_as_csv, load_from_csv, convert_coordinates_to_angles\n",
    "\n",
    "from load_data_fncs import load_all_data, get_exp_dates\n",
    "import sys\n",
    "sys.path.append(\"/Users/friederikebuck/Downloads/worm notes/worm_code/\")\n",
    "T = 1599\n",
    "_, _, full_beh_classification, full_beh_data = load_all_data()\n",
    "import ssm\n",
    "import pickle \n",
    "comp = \"mac\"\n",
    "if comp == \"hpc\":\n",
    "  project_dir = \"/ru-auth/local/home/fbuck/scratch/WholeBrainImaging/keypt_moseq/projects/_1/\"#sys.argv[1]+\"_1\"#/Volumes/FB1/moseq_project_dir/WholeBrainImagingAnalysis_1/\"\n",
    "  video_dir = \"/ru-auth/local/home/fbuck/scratch/WholeBrainImaging/outputs_hpc/\" #\"/Users/friederikebuck/Desktop/MBL/project/outputs/\"  #when al subdirs with vids or keypoints are stored \n",
    "  video_clip_dir = \"/ru-auth/local/home/fbuck/scratch/WholeBrainImaging/outputs_hpc/vid_clips/\"\n",
    "\n",
    "else: \n",
    "#   project_dir = \"/Volumes/FB1/moseq_project_dir_and_outputs/_1/\"\n",
    "# moseq_project_dir = \"\"\n",
    "    project_dir = \"/Volumes/FB1/moseq_project_dir_and_outputs/_1/\"\n",
    "    project_dir = \"/Volumes/FB_data_ana/moseq_project_dir_and_outputs/_1/\"\n",
    "    video_dir = \"/Users/friederikebuck/Desktop/MBL/project/outputs/\" #\"/Users/friederikebuck/Desktop/MBL/project/outputs/\"  #when al subdirs with vids or keypoints are stored \n",
    "    video_clip_dir = \"/Users/friederikebuck/Desktop/MBL/project/vid_clips/\"\n",
    "    save_dir = f\"/Volumes/FB_data_ana/moseq_project_dir_and_outputs_figs/\"\n",
    "\n",
    "    # os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# with open('/Users/friederikebuck/Desktop/MBL/project/keypt_moseq_coordinates_not_downsampled.pickle', 'rb') as handle:\n",
    "#    coordinates =  pickle.load(handle)\n",
    "   \n",
    "   \n",
    "kappas = np.logspace(3,7,5)\n",
    "kappas = [kappas[0]]\n",
    "decrease_kappa_factor = 10\n",
    "num_ar_iters = 50\n",
    "num_full_iters = 200\n",
    "time_bin = 10\n",
    "prefix = 'my_kappa_scan'\n",
    "# for kappa in kappas: #kappas[:2]\n",
    "kappa = kappas[0]\n",
    "print(f\"Fitting model with kappa={kappa}\")\n",
    "model_name = f'{prefix}-{kappa}'\n",
    "# fig_save_dir = os.path.join(save_dir, model_name)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "foldername = \"/Users/friederikebuck/Downloads/worm notes/processed_checkpts/test_rslds_QM_run_061325/model_selection/top_2_combined/\"\n",
    "items = np.array(os.listdir(foldername))\n",
    "folders = np.array([\".\" not in directory for directory in items], dtype=bool)\n",
    "folders = items[folders]\n",
    "\n",
    "folder = folders[0]\n",
    "\n",
    "\n",
    "with open(foldername+\"/Y.npy\", 'rb') as handle:  \n",
    "    Y = pickle.load(handle)\n",
    "\n",
    "\n",
    "with open(foldername+folder+\"/saved_data/prior.npy\", 'rb') as handle:\n",
    "    global_worm = pickle.load(handle)\n",
    "    global_worm.D = int(global_worm.D)\n",
    "\n",
    "with open(foldername+folder+\"/saved_data/prior_q.npy\", 'rb') as handle:\n",
    "    q = pickle.load(handle)\n",
    "    \n",
    "\n",
    "slds = global_worm\n",
    "\n",
    "neural_labels = np.load(foldername+\"/neurons.npy\", allow_pickle=True)\n",
    "\n",
    "\n",
    "print(np.array(Y).shape)\n",
    "\n",
    "print(len(neural_labels))\n",
    "\n",
    "\n",
    "\n",
    "slds = global_worm\n",
    "# get estimated latents, states\n",
    "q_x = q.mean_continuous_states\n",
    "q_z = [slds.most_likely_states(q_x[w], Y[w]) for w in range(len(q_x))]\n",
    "\n",
    "z = [beh_classification[\"is_fwd\"][0:1599]+ 2*beh_classification[\"is_rev\"][0:1599]+ 4*beh_classification[\"is_pause\"][0:1599]+3*beh_classification[\"is_turn\"][0:1599]-1 for beh_classification in full_beh_classification]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ac6363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c2cf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'plotly': 'https://cdn.plot.ly/plotly-2.18.0.min', 'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.3.2/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@4.2.5/dist/gridstack-h5', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'gridstack': {'exports': 'GridStack'}}});\n      require([\"plotly\"], function(Plotly) {\n\twindow.Plotly = Plotly\n\ton_load()\n      })\n      require([\"tabulator\"], function(Tabulator) {\n\twindow.Tabulator = Tabulator\n\ton_load()\n      })\n      require([\"moment\"], function(moment) {\n\twindow.moment = moment\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 5;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n    }    if (((window['Plotly'] !== undefined) && (!(window['Plotly'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/plotlyplot/plotly-2.18.0.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/js/tabulator.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/gridstack/gridstack@4.2.5/dist/gridstack-h5.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/0.14.4/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/jquery/jquery.slim.min.js\", \"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/plotlyplot/plotly-2.18.0.min.js\", \"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/js/tabulator.js\", \"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\", \"https://unpkg.com/@holoviz/panel@0.14.4/dist/panel.min.js\"];\n  var js_modules = [];\n  var css_urls = [\"https://cdn.holoviz.org/panel/0.14.4/dist/bundled/datatabulator/tabulator-tables@5.3.2/dist/css/tabulator_simple.min.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/debugger.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/alerts.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/card.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/widgets.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/markdown.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/json.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/loading.css\", \"https://cdn.holoviz.org/panel/0.14.4/dist/css/dataframe.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\"\\n    .bk.pn-loading.arc:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n      background-size: auto calc(min(50%, 400px));\\n    }\\n    \");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, js_modules, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.bk-root, .bk-root .bk:before, .bk-root .bk:after {\n",
       "  font-family: var(--jp-ui-font-size1);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 232\u001b[0m\n\u001b[1;32m    230\u001b[0m motor_states \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    231\u001b[0m state_to_label,  state_to_track_start_end_is \u001b[38;5;241m=\u001b[39m get_motor_state_start_end_is_rslds_start_end_specific_1(motor_states, rslds_states, z, q_z,  filter_duration_thres \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 232\u001b[0m state_to_track_start_end_is_over, state_to_track_start_end_is_under \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_motor_state_start_end_is_by_proportion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_to_track_start_end_is\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_to_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_z\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproportion_thres\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m state_to_title_lbl \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmotor_state,\u001b[38;5;250m \u001b[39m(rslds_start_state,\u001b[38;5;250m \u001b[39mrslds_end_state)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m state, (motor_state, (rslds_start_state, rslds_end_state)) \u001b[38;5;129;01min\u001b[39;00m state_to_label\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    235\u001b[0m get_grid_vids(state_to_track_start_end_is_under, state_to_label, state_to_title_lbl,  vid_name_supp\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_under\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/worm notes/worm_code/visualize_state_fncs.py:109\u001b[0m, in \u001b[0;36mfilter_motor_state_start_end_is_by_proportion\u001b[0;34m(state_to_track_start_end_is, state_to_lbl, q_z, proportion_thres)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (track, start, end) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(track_start_end_is):\n\u001b[1;32m    108\u001b[0m     n_frames \u001b[38;5;241m=\u001b[39m start\u001b[38;5;241m-\u001b[39mend\n\u001b[0;32m--> 109\u001b[0m     n_motor_state_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margwhere(\u001b[43mq_z\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m==\u001b[39mmotor_state)\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39msize\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_motor_state_counts\u001b[38;5;241m/\u001b[39mn_frames \u001b[38;5;241m>\u001b[39m proportion_thres:\n\u001b[1;32m    111\u001b[0m         over_thresh_start_end_is\u001b[38;5;241m.\u001b[39mappend(i)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "\n",
    "### get state mat (ie 0-8 dependineg on rsdls stae end state and motor state)\n",
    "### (later) label ethogram based on state ( tbh just mark single miss state + neural activity)\n",
    "### from stae mat get state start ends \n",
    "###from state start ends get clip start ends  \n",
    "###from track get jpeg dir\n",
    "###create jpeg dir \n",
    "\n",
    "import numpy as np\n",
    "import glob \n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import copy \n",
    "import traceback\n",
    "from rslds_motor_state_class_fncs import get_motor_state_start_end_is_rslds_start_end_specific\n",
    "sys.path.append(\"/Users/friederikebuck/Desktop/WormTracking/LargePlateWormTracker/\")\n",
    "from make_grid_vid_fncs import get_clip_windows_from_start_end_is, create_video_grid ,make_vid_clip, create_video_grid_color\n",
    "\n",
    "\n",
    "def get_frame_start_end_from_dir(full_jpeg_dir,frame_from_jpeg_dir_fnc,  sorted_img_file_names = None):\n",
    "    if sorted_img_file_names is  None: \n",
    "        img_file_names = glob.glob(os.path.join(full_jpeg_dir,\"*.jpeg\"))\n",
    "        sorted_img_file_names =  sorted(img_file_names, key = frame_from_jpeg_dir_fnc)\n",
    "    # if frame_start is None: \n",
    "    frame_start = frame_from_jpeg_dir_fnc(sorted_img_file_names[0])# int(Path(sorted_img_file_names[0]).stem.split(\"_\")[1])\n",
    "   \n",
    "    frame_end = frame_from_jpeg_dir_fnc(sorted_img_file_names[-1]) #int(Path(sorted_img_file_names[0]).stem.split(\"_\")[-1])\n",
    "    return frame_start, frame_end\n",
    "frame_from_jpeg_dir_1 = lambda img_file_name: int(Path(img_file_name).stem.split(\"_\")[1])\n",
    "frame_from_jpeg_dir_2 = lambda img_file_name: int(Path(img_file_name).stem)\n",
    "\n",
    "                                            \n",
    "\n",
    "def load_frames_from_full_png_dir(full_jpeg_dir, frame_from_jpeg_dir_fnc,  frame_start = None, frame_end = None, frame_size = (120,120), color = True):\n",
    "    img_file_names = glob.glob(full_jpeg_dir)#os.path.join(full_jpeg_dir,\"*.png\"))\n",
    "    print(img_file_names)\n",
    "    print(\"img_file_names[0]\", img_file_names[0])\n",
    "    sorted_img_file_names =  sorted(img_file_names, key = frame_from_jpeg_dir_fnc)#lambda img_file_name: int(Path(img_file_name).stem.split(\"_\")[1]))\n",
    "    print(\"sorted_img_file_names\", sorted_img_file_names)\n",
    "    if frame_start is None: \n",
    "        frame_start, _ = get_frame_start_end_from_dir(full_jpeg_dir,frame_from_jpeg_dir_fnc,  sorted_img_file_names = sorted_img_file_names)\n",
    "    if frame_end is None: \n",
    "        _, frame_end = get_frame_start_end_from_dir(full_jpeg_dir, frame_from_jpeg_dir_fnc, sorted_img_file_names = sorted_img_file_names)\n",
    "    n_frames = int(frame_end-frame_start)\n",
    "    if not color: \n",
    "        frames =  np.zeros((n_frames, frame_size[0], frame_size[1]))\n",
    "    else: \n",
    "        frames =  np.zeros((n_frames, frame_size[0], frame_size[1], 3))\n",
    "    print(full_jpeg_dir)\n",
    "    print(sorted_img_file_names)\n",
    "    dir_frame_start = frame_from_jpeg_dir_fnc(sorted_img_file_names[0]) #int(Path(sorted_img_file_names[0]).stem.split(\"_\")[1])\n",
    "    frame_start_i =  int(frame_start-dir_frame_start)\n",
    "    frame_end_i = int(frame_start_i+n_frames)\n",
    "    for i, frame_i in enumerate(range(frame_start_i, frame_end_i)):\n",
    "        try:\n",
    "            img_file_name = sorted_img_file_names[frame_i]\n",
    "         \n",
    "            if not color: \n",
    "                img = cv2.imread(img_file_name)[:,:,0]\n",
    "            else: \n",
    "                img = cv2.imread(img_file_name)[:,:,:]\n",
    "                \n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        except Exception as e:\n",
    "            # Catching a more general exception if specific ones are not known\n",
    "            print(f\"A general error occurred: {e}\")\n",
    "            traceback.print_exc()\n",
    "            if not color: \n",
    "                img = np.zeros(frame_size)\n",
    "            else: \n",
    "                img = np.zeros((frame_size[0], frame_size[1], 3))\n",
    "                    \n",
    "        frames[i] = img\n",
    "    return frames, frame_start, frame_end\n",
    "\n",
    "def get_track_start_end_is_from_date_to_start_ends(date_to_start_ends, i = 0):\n",
    "    track_to_date = {}\n",
    "    all_tracks =[]\n",
    "    all_starts = []\n",
    "    all_ends =[]\n",
    "    # i = 0\n",
    "    for date, (starts, ends) in date_to_start_ends.items():\n",
    "        all_tracks.append(np.ones(starts.shape[0])*i)\n",
    "        all_starts.append(starts)\n",
    "        all_ends.append(ends)\n",
    "        track_to_date[i] = date\n",
    "        i+=1\n",
    "    all_tracks = np.concatenate(all_tracks)[:, None]\n",
    "    all_starts = np.concatenate(all_starts)[:, None]\n",
    "    all_ends = np.concatenate(all_ends)[:, None]\n",
    "    return np.concatenate([all_tracks, all_starts, all_ends], axis = 1), track_to_date, i\n",
    "\n",
    "def annotate_frames(frames, event_bin, font_scale = 0.4): #copy frames and annotate with beh class; velocity; curvature\n",
    "    frames = copy.deepcopy(frames)\n",
    "    annotated_frames = np.zeros_like(frames)\n",
    "    for i, (frame, beh1)in enumerate(zip(frames,event_bin)):\n",
    "        \n",
    "                # Define the dimensions of the black area (e.g., 100 pixels wide and 50 pixels high)\n",
    "        black_width = 30\n",
    "        black_height = 30\n",
    "\n",
    "        # Define the top-left and bottom-right points of the rectangle\n",
    "        pt1 = (0, 0)  # Top-left corner of the image\n",
    "        pt2 = (black_width, black_height) # Bottom-right corner of the black area\n",
    "\n",
    "        # Draw a filled black rectangle\n",
    "        frame = cv2.rectangle(frame, pt1, pt2, (0, 0, 0), -1) \n",
    "            \n",
    "\n",
    "\n",
    "        if beh1: \n",
    "            dot_radius = 5\n",
    "            # dot_color = (255, 0, 255)\n",
    "            dot_color = (255, 255, 255)\n",
    "            pos = (60, 60)\n",
    "            frame = cv2.circle(frame, pos, dot_radius, dot_color, -1, cv2.LINE_AA)\n",
    "            \n",
    "        \n",
    "        annotated_frames[i] = frame\n",
    "    return annotated_frames\n",
    "def get_event_mat_from_track_start_end_is(track_start_end_is):\n",
    "    track_start_end_is = track_start_end_is.astype('int')\n",
    "    n_tracks = int(np.max(track_start_end_is[:, 0]))+1\n",
    "    n_frames = int(np.max(track_start_end_is[:, 2]))+1\n",
    "\n",
    "    \n",
    "    event_mat = np.zeros((n_tracks,n_frames ))\n",
    "    for track, start, end in track_start_end_is:\n",
    "        event_mat[track, start:end] = 1\n",
    "    return event_mat\n",
    "\n",
    "def get_frames_and_annotate(clip_start_ends, event_mat,  full_jpeg_dirs, frame_from_jpeg_dir_fnc, frame_size = (120,120), color = True ):\n",
    "    all_annotated_frames = []\n",
    "    all_frames = []\n",
    "    clip_start_ends = clip_start_ends.astype('int')\n",
    "    # clip_start_ends_all_tracks = clip_start_ends_all_tracks.astype('int')\n",
    "    \n",
    "    for i, (track , start, end) in enumerate( clip_start_ends):\n",
    "        # track_all_tracks, start_all_tracks, end_all_tracks = clip_start_ends_all_tracks[i]\n",
    "        \n",
    "        jpeg_dir = full_jpeg_dirs[i]\n",
    "        frames, _ ,_ = load_frames_from_full_png_dir(jpeg_dir, frame_from_jpeg_dir_fnc,  frame_start = start, frame_end = end, frame_size = frame_size, color = color)\n",
    "        # velocity = feature_to_vals[\"speed\"][i]\n",
    "        # event_mat = feature_to_vals[\"pause\"][i]\n",
    "        \n",
    "        # label_to_beh = {}\n",
    "        # annotated_frames = annotate_frames(frames, label_to_beh, beh, velocity, body_angle_mag)\n",
    "\n",
    "        annotated_frames =  annotate_frames(frames, event_mat[track, start:end], font_scale = 0.4)\n",
    "        all_annotated_frames.append(annotated_frames)\n",
    "        all_frames.append(frames)\n",
    "        \n",
    "        # track_to_annotated_frames.append((frames, annotated_frames))\n",
    "    return all_annotated_frames, all_frames\n",
    "def filter_single_frames(track_start_ends, dur_min = 2):\n",
    "    print(track_start_ends.shape)\n",
    "    durations = track_start_ends[:, 2]- track_start_ends[:, 1]\n",
    "    dur_i = np.argwhere(durations>=dur_min).flatten()\n",
    "    return track_start_ends[dur_i, :]\n",
    "\n",
    "def get_grid_vids(state_to_track_start_end_is, state_to_label, state_to_title_lbl,  vid_name_supp= \"\"):\n",
    "    for state, track_start_end_is in state_to_track_start_end_is.items():\n",
    "        # motor_state, (rslds_start_state, rslds_end_state) = state_to_label[state]\n",
    "        i = 0 \n",
    "\n",
    "        if track_start_end_is.size == 0: \n",
    "            continue\n",
    "\n",
    "        clip_start_ends = get_clip_windows_from_start_end_is(track_start_end_is, n_pre_frames, n_post_frames, max_n_clips = 25)\n",
    "        clipped_jpeg_dirs = [exp_date_to_jpeg_dir[track_to_date[track]] for track in clip_start_ends[:,0]]\n",
    "        event_mat = get_event_mat_from_track_start_end_is(track_start_end_is)\n",
    "        all_annotated_frames, all_frames = get_frames_and_annotate(clip_start_ends, event_mat,  clipped_jpeg_dirs, frame_from_jpeg_dir_1, frame_size =  (146,193), color = True )\n",
    "        # grid_frames = create_video_grid(all_frames, max_clip_len)\n",
    "        # grid_frames = create_video_grid_color(all_frames, max_clip_len)\n",
    "        annotated_grid_frames = create_video_grid_color(all_annotated_frames, max_clip_len)\n",
    "        vid_name = os.path.join(save_dir_name,f\"{state_to_title_lbl[state]}_ex_grid_{vid_name_supp}.mp4\")\n",
    "        print(\"vid_name\", vid_name)\n",
    "        make_vid_clip(annotated_grid_frames, vid_name, fps = vid_fps, quality=7)\n",
    "        i+=1\n",
    "        \n",
    "        \n",
    "from visualize_state_fncs import get_motor_state_start_end_is_rslds_start_end_specific_1, filter_motor_state_start_end_is_by_proportion\n",
    "jpeg_dir_basename = \"/Users/friederikebuck/Desktop/MBL/project/outputs/\"\n",
    "save_dir_name = \"/Users/friederikebuck/Desktop/MBL/project/outputs_grid_vids_colored_by_motor_state/\"\n",
    "\n",
    "os.makedirs(save_dir_name, exist_ok=True)\n",
    "# exp_to_jpeg_dir = lambda exp_date: os.path.join(jpeg_dir_basename,str(exp_date),\"imgs\", \"masked_imgs_resampled_timebin_1_target_length85\", \"*png\")\n",
    "exp_to_jpeg_dir = lambda exp_date: os.path.join(jpeg_dir_basename,str(exp_date),\"imgs1\", \"annotated_masked_imgs_resampled_timebin_1_target_length110\", \"*png\")\n",
    "\n",
    "\n",
    "time_bin = 1\n",
    "\n",
    "json_dir = \"/Users/friederikebuck/Desktop/MBL/project/data/Neuropal_no_heat/\"\n",
    "h5_dir =\"/Users/friederikebuck/Desktop/MBL/project/data/processed_h5/\"\n",
    "beh_data_dir_parent = \"/Users/friederikebuck/Desktop/MBL/project/outputs/\"\n",
    "        \n",
    "        \n",
    "# with open(f'/Users/friederikebuck/Desktop/MBL/project/beh_syllables_rslds_{model_name}_all_exps.pickle', 'rb') as handle: ##off by 10..figureo ut in which directio n\n",
    "#     a = pickle.load(handle)\n",
    "\n",
    "#     exp_dates, exp_date_to_syllables, date_to_discrete_rslds_states, exp_date_to_beh,syllables, \\\n",
    "#     syllables_all_dates, rslds_states_all_dates, syllables_all_dates_flat, \\\n",
    "#     rslds_states_all_dates_flat, beh_all_dates_flat, beh_all_dates = a\n",
    "    \n",
    "\n",
    "#motor_state_num_to_name\n",
    "\n",
    "\n",
    "directories = glob.glob(json_dir+\"*.json\") #get filename/paths of all the json files\n",
    "exp_dates = [directory.split(\"/\")[-1].split(\".\")[0] for directory in directories] #extract the exp_dates\n",
    "exp_date_to_jpeg_dir = {exp_date: exp_to_jpeg_dir(exp_date) for exp_date in exp_dates} ###for not wusing 10sx eesmapled..s hould use confocal..? go from rslds to 20 \n",
    "\n",
    "\n",
    "motor_state_to_rslds_state_to_exp_date_to_beh_start_end_is = {}\n",
    "motor_states = [0,1,2]\n",
    "\n",
    "fps = 1.66\n",
    "n_pre_frames = int(fps*10)\n",
    "n_post_frames = int(fps*30)\n",
    "vid_fps = 6\n",
    "max_clip_len = n_pre_frames+n_post_frames\n",
    "\n",
    "track_to_date = dict(enumerate(exp_dates))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rslds_states = [0,1,2]\n",
    "motor_states = [0,1,2]\n",
    "state_to_label,  state_to_track_start_end_is = get_motor_state_start_end_is_rslds_start_end_specific_1(motor_states, rslds_states, z, q_z,  filter_duration_thres = 1)\n",
    "state_to_track_start_end_is_over, state_to_track_start_end_is_under = filter_motor_state_start_end_is_by_proportion(state_to_track_start_end_is.astype('int'), state_to_label, q_z, proportion_thres = 0.6)\n",
    "state_to_title_lbl = {f\"{motor_state, (rslds_start_state, rslds_end_state)}\" for state, (motor_state, (rslds_start_state, rslds_end_state)) in state_to_label.items()}\n",
    "\n",
    "get_grid_vids(state_to_track_start_end_is_under, state_to_label, state_to_title_lbl,  vid_name_supp= \"_under\")\n",
    "get_grid_vids(state_to_track_start_end_is_under, state_to_label, state_to_title_lbl,  vid_name_supp= \"_over\")\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10313ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000,)\n",
      "(1600,)\n"
     ]
    }
   ],
   "source": [
    "# # @##Check 10x is \n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming 'your_file.csv' is a CSV file with numerical data\n",
    "# data = np.loadtxt('/Users/friederikebuck/Desktop/MBL/project/outputs/2022-06-28-01/csvs1/behavior_resampled_timebin_10.csv', delimiter=',')\n",
    "# print(data.shape)\n",
    "\n",
    "# data = np.loadtxt('/Users/friederikebuck/Desktop/MBL/project/outputs/2022-06-28-01/csvs1/behavior_resampled_timebin_1.csv', delimiter=',')\n",
    "# print(data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keypoint_moseq_ssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
