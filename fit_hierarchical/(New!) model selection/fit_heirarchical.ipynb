{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib widget\n",
    "import pickle\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list, dendrogram, fcluster\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, IntSlider\n",
    "import sys\n",
    "import glob\n",
    "sys.path.append(\"/Users/friederikebuck/Desktop/MBL/project/WholeBrainImagingAnalysis/collab/\")\n",
    "sys.path.append('/Users/bennetsakelaris/Documents/Obsidian Vault/Worms/wormcode/Code+Notes 09-24-24/collab/')\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from get_data.read_neuro_beh_data import get_exp_features\n",
    "from get_data.process_neural_data import get_derivative_of_neural_activity, get_neural_activity_from_labels, get_neural_activity_and_labels\n",
    "from beh_classification.behavior_features import get_behavior_features\n",
    "from beh_classification.get_behavior_classifications import get_behavior_classification\n",
    "from beh_classification.beh_classification_utils import get_start_end_is_of_ones_in_binary_array\n",
    "import socket\n",
    "import sklearn\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "def smooth_trace(raw_trace, sigma = 2):\n",
    "    denoised_data = gaussian_filter1d(raw_trace, sigma=sigma)\n",
    "    return denoised_data\n",
    "\n",
    "def shift_array_by_one(array):\n",
    "    _, n_dim = array.shape\n",
    "    tmp = np.ones((T, n_dim))*np.nan\n",
    "    tmp[1:] = array\n",
    "    array = tmp\n",
    "    return array\n",
    "\n",
    "\n",
    "def load_all_data(combine_classes = False):\n",
    "    # this just returns lists of traces, neural labels, and behavior for each worm\n",
    "    # Also includes dtrace\n",
    "    # be warned that all elements of the list have different shapes\n",
    "    combine_classes = np.mod(1+int(combine_classes),2)\n",
    "\n",
    "    host = socket.gethostname()[0:6]\n",
    "    if host == 'Bennet' or host == 'bennet' or 'northwestern' in socket.gethostname():\n",
    "        json_dir = \"/Users/bennetsakelaris/Documents/Obsidian Vault/worms/wormcode/data/Neuropal_no_heat/\"\n",
    "        h5_dir = \"/Users/bennetsakelaris/Documents/Obsidian Vault/worms/wormcode/data/processed_h5/\"\n",
    "        beh_data_dir_parent = \"/Users/bennetsakelaris/Desktop/behavior/outputs_sparse/\"\n",
    "    else:\n",
    "        json_dir = \"/Users/friederikebuck/Desktop/MBL/project/data/Neuropal_no_heat/\"\n",
    "        h5_dir =\"/Users/friederikebuck/Desktop/MBL/project/data/processed_h5/\"\n",
    "        beh_data_dir_parent = \"/Users/friederikebuck/Desktop/MBL/project/outputs/\"\n",
    "\n",
    "\n",
    "\n",
    "    directories = glob.glob(json_dir+\"*.json\") #get filename/paths of all the json files\n",
    "    exp_dates = [directory.split(\"/\")[-1].split(\".\")[0] for directory in directories] #extract the exp_dates\n",
    "    for i in range(len(exp_dates)):\n",
    "        print(\"Worm {}, date: {}\".format(i, exp_dates[i]))\n",
    "\n",
    "    full_traces = []\n",
    "    full_neural_labels = []\n",
    "    full_beh_classification = []\n",
    "    full_beh_data = []\n",
    "\n",
    "    for exp_date in exp_dates:\n",
    "        dt, T, beh_data, neural_data, neuroID_to_key = get_exp_features(exp_date, \n",
    "                                                                    json_dir = json_dir, \n",
    "                                                                    h5_dir = h5_dir)\n",
    "        behavior_features = get_behavior_features(beh_data)\n",
    "        beh_data.update(behavior_features)\n",
    "        behavior_classification = get_behavior_classification(beh_data)\n",
    "\n",
    "        beh_data_dir = os.path.join(beh_data_dir_parent, str(exp_date), \"csvs1\")\n",
    "        csv_name = os.path.join(beh_data_dir, \"beh_confocal.csv\")\n",
    "        beh_confocal = np.loadtxt(csv_name, delimiter=\",\")\n",
    "        z_beh = beh_confocal\n",
    "        \n",
    "        behavior_classification = {\n",
    "        \"is_fwd\": beh_confocal==0, \n",
    "        \"is_rev\": beh_confocal==1, \n",
    "        \"is_turn\": beh_confocal==2, \n",
    "        \"is_pause\":  beh_confocal==3,\n",
    "        }\n",
    "\n",
    "        neural_labels_orig, ftrace = get_neural_activity_and_labels(neural_data,  denoised = True)\n",
    "\n",
    "        dtrace = get_derivative_of_neural_activity(smooth_trace(ftrace.T,sigma=5).T, dframes = 1)\n",
    "        dtrace -= np.mean(dtrace,axis=0)\n",
    "        dtrace /= np.std(dtrace,axis=0)\n",
    "        traces = np.concatenate([ftrace[1:,: ],dtrace ], axis =1)\n",
    "        neural_labels = np.array([\"F - \"+ lbl[combine_classes] for lbl in neural_labels_orig]+\n",
    "                                [\"dF - \"+ lbl[combine_classes] for lbl in neural_labels_orig])\n",
    "        \n",
    "        full_traces.append(traces)\n",
    "        full_neural_labels.append(neural_labels)\n",
    "        full_beh_classification.append(behavior_classification)\n",
    "        full_beh_data.append(beh_data)\n",
    "\n",
    "    return full_traces, full_neural_labels, full_beh_classification, full_beh_data\n",
    "        \n",
    "\n",
    "\n",
    "def load_all_data_but_pretend_its_all_one_worm(combine_classes = False):\n",
    "    # This function concatenates everything into one worm and also returns a mask that tells you which neurons are and arent present\n",
    "    # Thing to ponder: adding columns of NaNs between worms would probably help the rSLDS learn better\n",
    "    full_traces, full_neural_labels, full_beh_classification, full_beh_data = load_all_data(combine_classes)\n",
    "\n",
    "    #get list of all neurons recorded in at least one trial\n",
    "    neural_labels_set = set()\n",
    "    for nl in full_neural_labels:\n",
    "        neural_labels_set = neural_labels_set.union(set(nl))\n",
    "    neural_labels = np.sort(list(neural_labels_set))\n",
    "\n",
    "    #now make the traces array, where the different recordings are concatenated and matched by neuron\n",
    "    #note: a couple of worms have 15 extra timesteps. I am truncating those to make things easier down the line\n",
    "    T = 1599\n",
    "    traces = np.zeros((T*len(full_traces), neural_labels.shape[0]))*np.nan #initialize traces to nan \n",
    "    #build the traces matrix\n",
    "    w=0\n",
    "    for tr, labels, in zip(full_traces, full_neural_labels): #for each worm, w\n",
    "        for i in range(tr.shape[1]): #for each neuron, i\n",
    "            label = labels[i] #get neuron name\n",
    "            idx = np.where(neural_labels==label)[0][0] #get index in full array\n",
    "            traces[w*T:(w+1)*T, idx] = tr[0:T,i] #put the neuron's activity in the appropriate spot\n",
    "        w+=1 #update worm index\n",
    "\n",
    "    \n",
    "\n",
    "    #set up behavior classification dict\n",
    "    behavior_classification = dict()\n",
    "    behavior_classification[\"is_turn\"] = np.zeros(T*len(full_traces))\n",
    "    behavior_classification[\"is_pause\"] = np.zeros(T*len(full_traces))\n",
    "    behavior_classification[\"is_rev\"] = np.zeros(T*len(full_traces))\n",
    "    behavior_classification[\"is_fwd\"] = np.zeros(T*len(full_traces))\n",
    "    behavior_classification[\"is_revturn\"] = np.zeros(T*len(full_traces))\n",
    "    behavior_classification[\"is_purerev\"] = np.zeros(T*len(full_traces))\n",
    "    behavior_classification[\"is_pureturn\"] = np.zeros(T*len(full_traces))\n",
    "    behavior_classification[\"is_rev_of_rev_turn\"] = np.zeros(T*len(full_traces))\n",
    "    behavior_classification[\"is_turn_of_rev_turn\"] = np.zeros(T*len(full_traces))\n",
    "\n",
    "    #fill it in\n",
    "    w=0\n",
    "    for bc in full_beh_classification:\n",
    "        for key in bc.keys():\n",
    "            behavior_classification[key][w*T:(w+1)*T] = bc[key][1:(T+1)] # shifting by one bc of the trace\n",
    "        w+=1 #update worm index\n",
    "\n",
    "    #return mask of nan data\n",
    "    mask =  (~np.isnan(traces)).astype(int)  # 1 where not naan (where exsts )\n",
    "    return traces, neural_labels, behavior_classification, mask\n",
    "\n",
    "# removes neurons that were only recorded in fewer than [threshold] experiments\n",
    "def remove_rare_neurons(traces, neural_labels, mask, threshold=10): \n",
    "    n_occurances = np.zeros(traces.shape[1]) #count the number of occurances for each neuron\n",
    "    for n in np.arange(0, traces.shape[1]):\n",
    "        n_occurances[n] = sum(~np.isnan(traces[np.arange(100, traces.shape[0], 1599),n]))\n",
    "    print(\"Removing {} neurons that are not recorded in more than {} experiments\".format(sum(n_occurances<=threshold)/2, threshold))\n",
    "    print(\"{} neurons remaining\".format(sum(n_occurances>threshold)/2))\n",
    "    \n",
    "    traces = traces[:, n_occurances>threshold]\n",
    "    neural_labels = neural_labels[n_occurances>threshold]\n",
    "    mask = mask[:, n_occurances>threshold]\n",
    "    return traces, neural_labels, mask\n",
    "\n",
    "def keep_from_list(traces, neural_labels, mask, to_keep):\n",
    "    n_occurances = np.zeros(traces.shape[1], dtype=bool) #see if each neuron is in to_keep\n",
    "    for n in np.arange(0, traces.shape[1]):\n",
    "        n_occurances[n] = neural_labels[n] in to_keep\n",
    "        print(n_occurances[n])\n",
    "\n",
    "    print(\"Removing {} neurons\".format((traces.shape[1]-sum(n_occurances))/2))\n",
    "    print(\"{} neurons remaining\".format(len(to_keep)/2))\n",
    "    \n",
    "    traces = traces[:, n_occurances]\n",
    "    neural_labels = neural_labels[n_occurances]\n",
    "    mask = mask[:, n_occurances]\n",
    "    return traces, neural_labels, mask\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "#color palette for plotting, colors as in make_behavior_ethogram\n",
    "palette = [\"coral\",     # forward\n",
    "           \"lightblue\", # reverse\n",
    "           \"darkgreen\", # turn\n",
    "           \"purple\",\"red\", \"yellow\", \"black\", \"pink\", \"grey\", \"cyan\"]    # pause\n",
    "cmap = LinearSegmentedColormap.from_list(\"behavior\", palette, N=len(palette))\n",
    "\n",
    "def states_to_changepoints(z):\n",
    "    assert z.ndim == 1\n",
    "    z = np.array(z)\n",
    "    return np.concatenate(([0], 1 + np.where(np.diff(z))[0], [z.size - 1]))\n",
    "\n",
    "def plot_2d_continuous_states(x, z,\n",
    "                              colors=palette,\n",
    "                              ax=None,\n",
    "                              inds=(0,1),\n",
    "                              figsize=(2.5, 2.5),\n",
    "                              **kwargs):\n",
    "\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "    cps = states_to_changepoints(z)\n",
    "\n",
    "    # Color denotes our inferred latent discrete state\n",
    "    for cp_start, cp_stop in zip(cps[:-1], cps[1:]):\n",
    "        ax.plot(x[cp_start:cp_stop + 1, inds[0]],\n",
    "                x[cp_start:cp_stop + 1, inds[1]],\n",
    "                 '-', color=colors[z[cp_start]],\n",
    "                **kwargs)\n",
    "\n",
    "def plot_most_likely_dynamics(model,\n",
    "    xlim=(-4, 4), ylim=(-3, 3), nxpts=20, nypts=20,\n",
    "    alpha=0.3, ax=None, figsize=(3, 3), color=None):\n",
    "    \n",
    "    K = model.K\n",
    "    assert model.D == 2\n",
    "    x = np.linspace(*xlim, nxpts)\n",
    "    y = np.linspace(*ylim, nypts)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    xy = np.column_stack((X.ravel(), Y.ravel()))\n",
    "\n",
    "    # Get the probability of each state at each xy location\n",
    "    try:\n",
    "        z = np.argmax(xy.dot(model.transitions.Rs.T) + model.transitions.r, axis=1)\n",
    "    except:\n",
    "        z = np.argmax(xy.dot(model.transitions.Rs.T), axis=1)\n",
    "\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "    for k, (A, b) in enumerate(zip(model.dynamics.As, model.dynamics.bs)):\n",
    "        dxydt_m = xy.dot(A.T) + b - xy\n",
    "\n",
    "        zk = z == k\n",
    "        if zk.sum(0) > 0:\n",
    "            if color == None:\n",
    "                ax.quiver(xy[zk, 0], xy[zk, 1],\n",
    "                        dxydt_m[zk, 0], dxydt_m[zk, 1],\n",
    "                        color=palette[k % len(palette)], alpha=alpha)\n",
    "            else:\n",
    "                ax.quiver(xy[zk, 0], xy[zk, 1],\n",
    "                        dxydt_m[zk, 0], dxydt_m[zk, 1],\n",
    "                        color=color, alpha=alpha)\n",
    "\n",
    "    ax.set_xlabel('$x_1$')\n",
    "    ax.set_ylabel('$x_2$')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_dynamic_landscape(model,k,\n",
    "    xlim=(-4, 4), ylim=(-3, 3), nxpts=20, nypts=20,\n",
    "    alpha=0.3, ax=None, figsize=(3, 3), color=None):\n",
    "    assert model.D == 2\n",
    "    K = model.K\n",
    "    x = np.linspace(*xlim, nxpts)\n",
    "    y = np.linspace(*ylim, nypts)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    xy = np.column_stack((X.ravel(), Y.ravel()))\n",
    "\n",
    "    # Get the probability of each state at each xy location\n",
    "    try:\n",
    "        z = np.argmax(xy.dot(model.transitions.Rs.T) + model.transitions.r, axis=1)\n",
    "    except:\n",
    "        z = np.argmax(xy.dot(model.transitions.Rs.T), axis=1)\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "    dxydt_m = xy.dot(model.dynamics.As[k].T) + model.dynamics.bs[k] - xy\n",
    "    dxydt_m_norm = np.zeros((len(dxydt_m)))\n",
    "    for xt in range(len(dxydt_m_norm)):\n",
    "        dxydt_m_norm[xt] = np.linalg.norm(dxydt_m[xt,:])\n",
    "\n",
    "    ax.plot_trisurf(xy[:,0], xy[:,1], dxydt_m_norm, cmap = \"coolwarm\", linewidth=0, antialiased=False)\n",
    "\n",
    "    ax.set_xlabel('$x_1$')\n",
    "    ax.set_ylabel('$x_2$')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return ax\n",
    "\n",
    "def plot_most_likely_dynamics_new(model, test_x, test_z, pca_x, pc3 = 0, input_str=0, input_id=0, ax=None, lim = None, plot_trajectory=True, inds=(0,1), do_pca=True, velocity=False):\n",
    "    ind1,ind2 = inds\n",
    "    pca = PCA(n_components=pca_x.shape[1])\n",
    "    x_centered = pca_x - np.mean(pca_x, axis=0)\n",
    "    pca.fit(x_centered)  # X is your trajectory data matrix\n",
    "    X_pca = pca.transform(test_x - np.mean(pca_x, axis=0) )\n",
    "    \n",
    "    K = model.K\n",
    "    # Define grid limits based on PCA-transformed trajectory\n",
    "    if lim == None:\n",
    "        x_min, x_max = X_pca[:, ind1].min() - 3, X_pca[:, ind1].max() + 3\n",
    "        y_min, y_max = X_pca[:, ind2].min() - 3, X_pca[:, ind2].max() + 3\n",
    "        lim = [x_min, x_max, y_min, y_max]\n",
    "    else:\n",
    "        x_min = lim[0]\n",
    "        x_max = lim[1]\n",
    "        y_min = lim[2]\n",
    "        y_max = lim[3]\n",
    "\n",
    "    # Create a grid of points\n",
    "    x = np.linspace(x_min, x_max, 30)  # 30 grid points along x-axis\n",
    "    y = np.linspace(y_min, y_max, 30)  # 30 grid points along y-axis\n",
    "    X_grid, Y_grid = np.meshgrid(x, y)  # Create the grid\n",
    "\n",
    "    # Inverse transform to get high-dimensional coordinates of grid points\n",
    "    xy = np.column_stack(pca_x.shape[1]*[0*Y_grid.ravel()])\n",
    "    xy[:,ind1] = X_grid.ravel()\n",
    "    xy[:,ind2] = Y_grid.ravel()\n",
    "\n",
    "    if do_pca:\n",
    "        xy_high_dim = pca.inverse_transform(xy)  # Map back to original space\n",
    "    else:\n",
    "        xy_high_dim = xy\n",
    "\n",
    "    # Get the probability of each state at each xy location\n",
    "    try:\n",
    "        z = np.argmax(xy_high_dim.dot(model.transitions.Rs.T) + model.transitions.r, axis=1)\n",
    "    except:\n",
    "        z = np.argmax(xy_high_dim.dot(model.transitions.Rs.T), axis=1)\n",
    "\n",
    "    if ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "    velocity_magnitudes = np.zeros_like(X_grid.ravel())\n",
    "\n",
    "    if model.M == 0:\n",
    "        for k, (A, b) in enumerate(zip(model.dynamics.As, model.dynamics.bs)):\n",
    "            next_step_high_dim = xy_high_dim @ A.T + b  # x_t+1 = Ax_t + b\n",
    "            # Map back to PCA space for visualization\n",
    "            if do_pca:\n",
    "                next_step_pca = next_step_high_dim @ pca.components_.T\n",
    "            else:\n",
    "                next_step_pca = next_step_high_dim\n",
    "\n",
    "            zk = z == k\n",
    "            if zk.sum(0) > 0:\n",
    "                ax.quiver(xy[zk, ind1], xy[zk, ind2],\n",
    "                        next_step_pca[zk, ind1]-xy[zk,ind1], next_step_pca[zk, ind2]-xy[zk,ind2],\n",
    "                        color=palette[k % len(palette)], alpha=1)\n",
    "            velocity_magnitudes[zk] = np.linalg.norm(next_step_pca[zk] - xy[zk], axis=1)\n",
    "    else:\n",
    "        for k, (A, b, V) in enumerate(zip(model.dynamics.As, model.dynamics.bs, model.dynamics.Vs)):\n",
    "            next_step_high_dim = xy_high_dim @ A.T + b + input_str*V[:,input_id] # x_t+1 = Ax_t + b\n",
    "            # Map back to PCA space for visualization\n",
    "            if do_pca:\n",
    "                next_step_pca = next_step_high_dim @ pca.components_.T\n",
    "            else:\n",
    "                next_step_pca = next_step_high_dim\n",
    "\n",
    "            zk = z == k\n",
    "            if zk.sum(0) > 0:\n",
    "                ax.quiver(xy[zk, ind1], xy[zk, ind2],\n",
    "                        next_step_pca[zk, ind1]-xy[zk,ind1], next_step_pca[zk, ind2]-xy[zk,ind2],\n",
    "                        color=palette[k % len(palette)], alpha=1)\n",
    "                velocity_magnitudes[zk] = np.linalg.norm(next_step_pca[zk] - xy[zk], axis=1)\n",
    "            \n",
    "    if velocity:\n",
    "        ax.cla()\n",
    "         # Reshape velocity magnitudes to match grid\n",
    "        velocity_magnitudes = velocity_magnitudes.reshape(30, 30)\n",
    "\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "        # Plot the velocity heatmap\n",
    "        heatmap = ax.pcolormesh(X_grid, Y_grid, velocity_magnitudes, cmap=\"Purples\", shading='auto')\n",
    "        plt.colorbar(heatmap, ax=ax, label=\"Velocity Magnitude\")\n",
    "                \n",
    "    ax.set_xlabel('$x_1$')\n",
    "    ax.set_ylabel('$x_2$')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if plot_trajectory:\n",
    "        if do_pca:\n",
    "            plot_2d_continuous_states(X_pca, test_z, ax=ax, inds=inds)\n",
    "        else:\n",
    "            plot_2d_continuous_states(test_x, test_z, ax=ax, inds=inds)\n",
    "    ax.set_xlim(x_min+2, x_max-2)\n",
    "    ax.set_ylim(y_min+2, y_max-2)\n",
    "\n",
    "    return ax, lim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all worms\n",
    "Look at shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worm 0, date: 2022-06-14-01\n",
      "Worm 1, date: 2023-01-23-08\n",
      "Worm 2, date: 2022-06-28-07\n",
      "Worm 3, date: 2022-07-15-12\n",
      "Worm 4, date: 2023-01-19-01\n",
      "Worm 5, date: 2022-08-02-01\n",
      "Worm 6, date: 2022-06-14-07\n",
      "Worm 7, date: 2022-06-28-01\n",
      "Worm 8, date: 2023-01-23-15\n",
      "Worm 9, date: 2022-07-26-01\n",
      "Worm 10, date: 2023-01-19-15\n",
      "Worm 11, date: 2023-03-07-01\n",
      "Worm 12, date: 2022-06-14-13\n",
      "Worm 13, date: 2023-01-23-21\n",
      "Worm 14, date: 2023-01-19-22\n",
      "Worm 15, date: 2023-01-23-01\n",
      "Worm 16, date: 2023-01-17-01\n",
      "Worm 17, date: 2022-07-20-01\n",
      "Worm 18, date: 2023-01-09-28\n",
      "Worm 19, date: 2023-01-19-08\n",
      "Worm 20, date: 2022-07-15-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/friederikebuck/Desktop/MBL/project/WholeBrainImagingAnalysis/collab/beh_classification/behavior_features.py:11: RuntimeWarning: Mean of empty slice\n",
      "  body_angles = body_angles-np.nanmean(body_angles, axis = 1)[:, None]\n",
      "/Users/friederikebuck/Desktop/MBL/project/WholeBrainImagingAnalysis/collab/beh_classification/behavior_features.py:15: RuntimeWarning: Mean of empty slice\n",
      "  centroids = np.nanmean(midlines, axis = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worm 0 number of neurons: 79.0, timesteps: 1599\n",
      "Worm 1 number of neurons: 88.0, timesteps: 1599\n",
      "Worm 2 number of neurons: 85.0, timesteps: 1599\n",
      "Worm 3 number of neurons: 93.0, timesteps: 1599\n",
      "Worm 4 number of neurons: 73.0, timesteps: 1599\n",
      "Worm 5 number of neurons: 114.0, timesteps: 1599\n",
      "Worm 6 number of neurons: 88.0, timesteps: 1599\n",
      "Worm 7 number of neurons: 78.0, timesteps: 1599\n",
      "Worm 8 number of neurons: 101.0, timesteps: 1599\n",
      "Worm 9 number of neurons: 71.0, timesteps: 1599\n",
      "Worm 10 number of neurons: 63.0, timesteps: 1599\n",
      "Worm 11 number of neurons: 85.0, timesteps: 1599\n",
      "Worm 12 number of neurons: 97.0, timesteps: 1599\n",
      "Worm 13 number of neurons: 99.0, timesteps: 1599\n",
      "Worm 14 number of neurons: 96.0, timesteps: 1599\n",
      "Worm 15 number of neurons: 90.0, timesteps: 1599\n",
      "Worm 16 number of neurons: 95.0, timesteps: 1614\n",
      "Worm 17 number of neurons: 97.0, timesteps: 1599\n",
      "Worm 18 number of neurons: 94.0, timesteps: 1614\n",
      "Worm 19 number of neurons: 89.0, timesteps: 1599\n",
      "Worm 20 number of neurons: 71.0, timesteps: 1599\n",
      "Worm 0, date: 2022-06-14-01\n",
      "Worm 1, date: 2023-01-23-08\n",
      "Worm 2, date: 2022-06-28-07\n",
      "Worm 3, date: 2022-07-15-12\n",
      "Worm 4, date: 2023-01-19-01\n",
      "Worm 5, date: 2022-08-02-01\n",
      "Worm 6, date: 2022-06-14-07\n",
      "Worm 7, date: 2022-06-28-01\n",
      "Worm 8, date: 2023-01-23-15\n",
      "Worm 9, date: 2022-07-26-01\n",
      "Worm 10, date: 2023-01-19-15\n",
      "Worm 11, date: 2023-03-07-01\n",
      "Worm 12, date: 2022-06-14-13\n",
      "Worm 13, date: 2023-01-23-21\n",
      "Worm 14, date: 2023-01-19-22\n",
      "Worm 15, date: 2023-01-23-01\n",
      "Worm 16, date: 2023-01-17-01\n",
      "Worm 17, date: 2022-07-20-01\n",
      "Worm 18, date: 2023-01-09-28\n",
      "Worm 19, date: 2023-01-19-08\n",
      "Worm 20, date: 2022-07-15-06\n"
     ]
    }
   ],
   "source": [
    "T = 1599\n",
    "full_traces, full_neural_labels, full_beh_classification, full_beh_data = load_all_data(combine_classes=True)\n",
    "for i in range(len(full_beh_classification)):\n",
    "    print(\"Worm {} number of neurons: {}, timesteps: {}\".format(i, full_traces[i].shape[1]/2, full_traces[i].shape[0])) #dividing neurons by 2 to include both traces and dtraces\n",
    "\n",
    "traces_all, neural_labels_all, behavior_classification, mask_all = load_all_data_but_pretend_its_all_one_worm(combine_classes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subsample neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "Removing 27.0 neurons\n",
      "47.0 neurons remaining\n",
      "['F - AIN', 'F - VB02', 'dF - ADA', 'dF - AVE', 'F - RID', 'F - AVA', 'dF - BAG', 'dF - AIY', 'dF - RIB', 'F - URB', 'F - ADA', 'F - AWC', 'F - SAA', 'dF - AUA', 'dF - SMD', 'dF - AIN', 'dF - RMD', 'dF - VB02', 'F - RIV', 'F - SIB', 'dF - AVA', 'dF - RIC', 'F - IL1', 'dF - AWB', 'F - AUA', 'dF - URX', 'F - CEP', 'dF - CEP', 'dF - AQR', 'dF - AIB', 'F - AVL', 'F - AVK', 'dF - RIA', 'F - RIP', 'F - SMD', 'F - RME', 'F - AVJ', 'dF - OLQ', 'dF - RME', 'F - OLL', 'dF - ASK', 'dF - SAA', 'F - AWB', 'dF - RIV', 'dF - RID', 'dF - SMB', 'dF - RIH', 'F - RMD', 'dF - AVJ', 'dF - RMF', 'dF - RIS', 'dF - URB', 'F - RMF', 'dF - URY', 'dF - SIA', 'F - SIA', 'F - BAG', 'F - SMB', 'F - URX', 'dF - SIB', 'F - RIC', 'F - RIM', 'F - AVB', 'dF - RIP', 'dF - ASH', 'dF - AVL', 'F - AVE', 'dF - OLL', 'F - AQR', 'F - RIH', 'F - ASK', 'dF - AWA', 'dF - AVK', 'F - RIR', 'dF - ASG', 'F - AWA', 'dF - RIR', 'F - RIS', 'dF - RIM', 'F - URY', 'dF - AVB', 'F - AIB', 'F - AIM', 'F - RIB', 'F - ASG', 'dF - AIM', 'F - AIY', 'dF - AWC', 'F - AIZ', 'F - ASH', 'F - RIA', 'F - OLQ', 'dF - IL1', 'dF - AIZ']\n"
     ]
    }
   ],
   "source": [
    "# #### OPTION 1: donut neurons\n",
    "# to_keep = [\"RIM\", \"AVA\",\"AVE\", \"RIB\", \"AVB\", \"AIB\", \"RID\", \"RME\", \"ASG\", \"SIB\", \"RIV\", \"VB02\", \"BAG\", \"AUA\", \"AVL\", \"URY\", \"AQR\", \"AIA\", \"AIM\", \"IL1\"] # top 20 donuty neurons\n",
    "# neurons_to_keep = [\"F - \" + neuron for neuron in to_keep] + [\"dF - \" + neuron for neuron in to_keep]\n",
    "# traces, neural_labels, mask = keep_from_list(traces_all, neural_labels_all, mask_all, neurons_to_keep)\n",
    "\n",
    "#### OPTION 2: keep neurons based on how often theyre recorded (threshold = minimum number of worms the neurons are present in)\n",
    "#traces, neural_labels, mask = remove_rare_neurons(traces_all, neural_labels_all, mask_all, threshold=2)\n",
    "\n",
    "\n",
    "# #### OPTION 3: keep neurons based on how well the model can predict their activity\n",
    "foldername = \"for_neural_var/\"\n",
    "items = np.array(os.listdir(foldername))\n",
    "folders = np.array([\".\" not in directory for directory in items], dtype=bool)\n",
    "folders = items[folders]\n",
    "folder = folders[0]\n",
    "\n",
    "neural_var_explained = np.load(foldername+folder+\"/neural_var_explained.npy\", allow_pickle=True)\n",
    "to_remove = np.nanmean(neural_var_explained.T, axis=0)<0.3 #var explained threshold\n",
    "classes = [neuron.split(' - ')[1] for neuron in neural_labels_all[to_remove] ]\n",
    "classes = np.unique(classes)\n",
    "Fs = [\"F - \" + classs for classs in classes]\n",
    "dFs = [\"dF - \" + classs for classs in classes]\n",
    "neurons_to_remove = Fs + dFs\n",
    "neurons_to_keep = list(set(neural_labels_all) - set(neurons_to_remove))\n",
    "traces, neural_labels, mask = keep_from_list(traces_all, neural_labels_all, mask_all, neurons_to_keep)\n",
    "print(neurons_to_keep)# oh doe sthis no keep dF and F togetoth? \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rSLDS time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssm\n",
    "from ssm.util import random_rotation, find_permutation\n",
    "from ssm.plots import plot_dynamics_2d\n",
    "from ssm.extensions.mp_srslds.transitions_ext import StickyRecurrentOnlyTransitions\n",
    "#rSLDS assumptions\n",
    "transition = \"recurrent_only\"\n",
    "#transition = \"sticky_recurrent_only\"\n",
    "dynamic = \"diagonal_gaussian\"\n",
    "emission = \"gaussian_orthog\"\n",
    "\n",
    "np.random.seed(0)\n",
    "Y = np.copy(traces)\n",
    "Y[np.isnan(Y)] = 0\n",
    "Y = [Y[i*1599:1599*(i+1)] for i in range(len(full_traces))] #convert to list where each element is the time series of a different worm\n",
    "mask=mask.astype(bool)\n",
    "masks = [mask[i*1599:1599*(i+1)] for i in range(len(full_traces))] #likewise for mask\n",
    "print(len(Y))\n",
    "print(Y[5].shape)\n",
    "tags = [None]*len(masks)\n",
    "# set up a single behavioral state array (\"z\" in the language of scott): \n",
    "#   0: is_fwd\n",
    "#   1: is_rev\n",
    "#   2: is_turn\n",
    "z = behavior_classification[\"is_fwd\"]+ 2*behavior_classification[\"is_rev\"]+ 4*behavior_classification[\"is_pause\"]+3*behavior_classification[\"is_turn\"]-1\n",
    "z = z.astype(int)\n",
    "\n",
    "emissions_dim = neural_labels.shape[0]\n",
    "\n",
    "\n",
    "def train_global_rslds(n_disc_states, latent_dim, i_want_to_plot_fitting = False):\n",
    "    # Create the model and initialize its parameters\n",
    "    slds = ssm.SLDS(emissions_dim, n_disc_states, latent_dim,\n",
    "                    transitions=transition,\n",
    "                    dynamics=dynamic, \n",
    "                    emissions=emission, \n",
    "                    single_subspace=True, verbose=False)\n",
    "\n",
    "\n",
    "    # Fit the model using Laplace-EM with a structured variational posterior\n",
    "    q_elbos, q = slds.fit(Y, method=\"laplace_em\", #default\n",
    "                                variational_posterior=\"structured_meanfield\", #default\n",
    "                                num_iters=50, alpha=0, masks=masks, tags=tags, num_init_restarts=15, verbose=False)\n",
    "    \n",
    "    try:\n",
    "        slds.permute(find_permutation(z[0:1599], slds.most_likely_states(q.mean_continuous_states[0], Y[0])))\n",
    "        print(q.mean_continuous_states[0].shape)\n",
    "        print(Y[0].shape)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if i_want_to_plot_fitting:\n",
    "        # plot results of SLDS fitting to make sure it converged\n",
    "        fig, axs = plt.subplots(1, 1)\n",
    "        axs.plot(q_elbos)\n",
    "        axs.set_xlabel(\"Iteration\")\n",
    "        axs.set_ylabel(\"ELBO\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "    return slds, q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical rSLDS\n",
    "The gist\n",
    "* Each worm gets its own rSLDS\n",
    "* the worm-specific rSLDSs are loosely tied together through a shared prior\n",
    "\n",
    "How to find shared prior? A couple of options\n",
    "* iteratively: one fitting step of each rslds -> avg parameters across worms (update prior) -> resample rslds from updated prior -> repeat\n",
    "* two-stage: completely fit all rslds -> avg parameters across worms (update prior) -> resample rslds from updated prior -> fit again, this time with updated prior -> done\n",
    "* train a rslds jointly on all data (similar to the iterative approach but without resampling) -- this is what i did in this version bc its much faster and doesnt seem to give very different results from the others\n",
    "I \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a bunch of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy, copy\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "def initialize_global_prior(model):\n",
    "    K = len(model.dynamics.As)  \n",
    "    latent_dim = model.D  \n",
    "\n",
    "    # Initialize global prior\n",
    "    global_prior = {\n",
    "        \"A_mean\": np.zeros((K, latent_dim, latent_dim)),\n",
    "        \"b_mean\": np.zeros((K, latent_dim)),\n",
    "        \"Q_prior\": {\"Psi\": np.eye(latent_dim), \"nu\": latent_dim + 2},\n",
    "        \"r_mean\": np.zeros(K),\n",
    "        \"R_mean\": np.zeros((K, latent_dim))\n",
    "    }\n",
    "\n",
    "    # Populate dynamics matrices A and biases b\n",
    "    global_prior[\"A_mean\"] = np.stack(model.dynamics.As, axis=0)\n",
    "    global_prior[\"b_mean\"] = np.stack(model.dynamics.bs, axis=0)\n",
    "    \n",
    "    # Populate noise covariance prior\n",
    "    global_prior[\"Q_prior\"][\"Psi\"] = np.mean(np.stack(model.dynamics.Sigmas, axis=0), axis=0)\n",
    "    \n",
    "    # Populate transition parameters\n",
    "    global_prior[\"r_mean\"] = model.transitions.r\n",
    "    global_prior[\"R_mean\"] = np.stack(model.transitions.Rs, axis=0)\n",
    "    \n",
    "    return global_prior\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def update_global_prior(worm_models, global_prior):\n",
    "    num_worms = len(worm_models)\n",
    "    K = worm_models[0].K \n",
    "    \n",
    "    # Initialize arrays \n",
    "    A_sum = np.zeros((K, worm_models[0].D, worm_models[0].D))\n",
    "    b_sum = np.zeros((K, worm_models[0].D))\n",
    "    Q_sum = np.zeros((K, worm_models[0].D, worm_models[0].D))\n",
    "    r_sum = np.zeros(K)\n",
    "    R_sum = np.zeros((K, worm_models[0].D))\n",
    "    \n",
    "\n",
    "     # Compute mean across worms\n",
    "    for model in worm_models:\n",
    "        A_sum += np.stack(model.dynamics.As, axis=0)  \n",
    "        b_sum += np.stack(model.dynamics.bs, axis=0) \n",
    "        Q_sum += np.stack(model.dynamics.Sigmas, axis=0) \n",
    "        r_sum += model.transitions.r \n",
    "        R_sum += np.stack(model.transitions.Rs, axis=0)  \n",
    "    \n",
    "   \n",
    "    global_prior[\"A_mean\"] = A_sum / num_worms\n",
    "    global_prior[\"b_mean\"] = b_sum / num_worms\n",
    "    global_prior[\"Q_prior\"][\"Psi\"] = np.mean(Q_sum, axis=0)  # Update noise prior Psi # review\n",
    "\n",
    "    global_prior[\"r_mean\"] = r_sum / num_worms\n",
    "    global_prior[\"R_mean\"] = R_sum / num_worms\n",
    "    \n",
    "    return global_prior\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def resample_parameters(model, global_prior):\n",
    "    K = model.K\n",
    "\n",
    "    model.dynamics.As = np.array([\n",
    "        np.random.multivariate_normal(global_prior[\"A_mean\"][k].flatten(), global_prior[\"A_cov\"]).reshape(model.D, model.D) # so A_cov never updates? \n",
    "        for k in range(K)\n",
    "    ])\n",
    "    \n",
    "    model.dynamics.bs = np.array([\n",
    "        np.random.multivariate_normal(global_prior[\"b_mean\"][k], global_prior[\"b_cov\"])\n",
    "        for k in range(K)\n",
    "    ])\n",
    "\n",
    "    model.dynamics.Sigmas = np.array([\n",
    "        scipy.stats.invwishart.rvs(scale=global_prior[\"Q_prior\"][\"Psi\"], df=global_prior[\"Q_prior\"][\"nu\"])\n",
    "        for k in range(K)\n",
    "    ])\n",
    "\n",
    "    model.transitions.r = np.random.multivariate_normal(global_prior[\"r_mean\"], global_prior[\"r_cov\"])\n",
    "    model.transitions.Rs = np.array([\n",
    "        np.random.multivariate_normal(global_prior[\"R_mean\"][k], global_prior[\"R_cov\"])\n",
    "        for k in range(K)\n",
    "    ])\n",
    "\n",
    "def initialize_worm_models(slds):\n",
    "    K = slds.K\n",
    "    latent_dim = slds.D\n",
    "    # Shared prior\n",
    "    global_prior = {\n",
    "        \"A_mean\": np.zeros((K, latent_dim, latent_dim)),# K is num discrete states  # this iwll be replaced by A_mean of all worms \n",
    "        \"A_cov\": np.eye(latent_dim * latent_dim)*0.04,\n",
    "        \"b_mean\": np.zeros((K, latent_dim)), # this iwll be replaced by b_mean of all worms \n",
    "        \"b_cov\": np.eye(latent_dim)*.13,\n",
    "        \"Q_prior\": {\"Psi\": np.eye(latent_dim), \"nu\": latent_dim + 2},# this iwll be replaced by mean Q_sum of all worms \n",
    "        \"r_mean\": np.zeros(K),  # will be updated by r mean .. review tha t r_mean is' and what R_mean is \n",
    "        \"r_cov\": np.eye(K),\n",
    "        \"R_mean\": np.zeros((K, latent_dim)), # will be updated by r mean \n",
    "        \"R_cov\": np.eye(latent_dim)*.5,\n",
    "    }\n",
    "\n",
    "    # Worm-specific models\n",
    "    worm_models = []\n",
    "    for worm_data in Y:\n",
    "        model = copy.deepcopy(slds)\n",
    "        worm_models.append(model)\n",
    "        \n",
    "    return global_prior, worm_models\n",
    "\n",
    "\n",
    "\n",
    "def plot_and_save(worm_models, qs, filestr):\n",
    "    q_z_full = []\n",
    "    q_x_full = []\n",
    "    n_disc_states = worm_models[0].K\n",
    "\n",
    "\n",
    "    for w, model in enumerate(worm_models):\n",
    "        q = qs[w]\n",
    "            \n",
    "        # Get the posterior mean of the continuous states\n",
    "        q_x = q.mean_continuous_states[0]\n",
    "        Y_w = Y[w]\n",
    "        \n",
    "        z_w = z[w*1599:(w+1)*1599]\n",
    "        q_z = model.most_likely_states(q_x, Y_w) #this is estimated behavioral state\n",
    "        q_x_full.append(q_x)\n",
    "\n",
    "        try:\n",
    "            model.permute(find_permutation(z_w, q_z))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        q_z = model.most_likely_states(q_x, Y_w) #this is estimated behavioral state\n",
    "        q_z_full.append(q_z)\n",
    "\n",
    "        # Plot state overlap as percent of actual\n",
    "        overlap = np.zeros((3, n_disc_states))\n",
    "        denom = []\n",
    "        for i in range(3):\n",
    "            denom.append(sum(z_w==i))\n",
    "        for t in range(len(z_w)):\n",
    "            overlap[z_w[t],q_z[t]] +=1.0/denom[z_w[t]]\n",
    "        if True:\n",
    "            fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "            im = ax.imshow(overlap, vmin=0, vmax=1)\n",
    "            ax.set_xlabel(\"estimated\")\n",
    "            ax.set_ylabel(\"true\")\n",
    "            fig.colorbar(im, ax=ax)\n",
    "            ax.set_yticks(np.arange(0,3), labels=[\"forwards\", \"backwards\", \"turning\"], rotation=0)    \n",
    "            ax.set_xticks(np.arange(0,n_disc_states))\n",
    "            ax.set_title(\"State overlap, worm {}\".format(w))\n",
    "            fig.savefig(filestr+\"/saved_figs/\"+f\"worm{w}_overlap.png\")\n",
    "            plt.close()\n",
    "\n",
    "            # Plot the true and inferred states\n",
    "            fig, axs = plt.subplots(2,1, figsize=(18,6))\n",
    "            axs[0].imshow(z_w[None,:], aspect=\"auto\", cmap=cmap, alpha=0.3, vmin=0, vmax=len(palette))\n",
    "            axs[1].imshow(q_z[None,:], aspect=\"auto\", cmap=cmap, alpha=0.3, vmin=0, vmax=len(palette))\n",
    "            axs[0].set_yticks([]); axs[1].set_yticks([])\n",
    "            axs[0].set_title(\"Given labels\"); axs[1].set_title(\"Inferred by rSLDS\")\n",
    "            axs[1].set_xticks([])\n",
    "            fig.savefig(filestr+\"/saved_figs/\"+f\"worm{w}_states.png\")\n",
    "            plt.close()\n",
    "            \n",
    "\n",
    "\n",
    "        #phase portraits\n",
    "        pca = PCA() \n",
    "        pca_x = pca.fit_transform(q_x) #do pca\n",
    "        id1=0 #choose which 2 PCs you want to plot\n",
    "        id2=1\n",
    "        W = pca.components_[[id1,id2],:]  # get components\n",
    "\n",
    "\n",
    "        # Create the PCA-space rslds model and initialize its parameters\n",
    "        # This is done so we can feed it into to scotts handy plot_most_likely_dynamics function\n",
    "        pca_slds = ssm.SLDS(emissions_dim, n_disc_states, 2,\n",
    "                        transitions=transition,\n",
    "                        dynamics=dynamic,\n",
    "                        emissions=emission,\n",
    "                        single_subspace=True)\n",
    "\n",
    "\n",
    "        #plot the phase portraits in PCA world\n",
    "        for k in range(n_disc_states):\n",
    "            # Dimensionality-reduced versions of A and b\n",
    "            A_reduced = W @ model.dynamics.As[k] @ W.T\n",
    "            b_reduced = W @ model.dynamics.bs[k]\n",
    "            R_reduced = W @ model.transitions.Rs[k]\n",
    "            pca_slds.dynamics.As[k] = A_reduced\n",
    "            pca_slds.dynamics.bs[k] = b_reduced\n",
    "            pca_slds.transitions.Rs[k] = R_reduced\n",
    "            pca_slds.transitions.r[k] = model.transitions.r[k]\n",
    "\n",
    "        if True:\n",
    "            fig, ax = plt.subplots(1,1, figsize=(8,6))\n",
    "            plot_2d_continuous_states(pca_x, q_z, ax=ax, inds=(id1, id2), lw=1, alpha=0.4)\n",
    "\n",
    "            lim = abs(pca_x).max(axis=0) + 1\n",
    "            try:\n",
    "                pca_slds.permute(find_permutation(z_w, q_z))\n",
    "            except:\n",
    "                pass\n",
    "            plot_most_likely_dynamics(pca_slds, xlim=(-lim[0], lim[0]), ylim=(-lim[1], lim[1]), ax=ax)\n",
    "            ax.set_title(\"PCs {} and {}, variance explained: {}\".format(1+id1, 1+id2, sum(pca.explained_variance_ratio_[[id1,id2]])))\n",
    "\n",
    "\n",
    "            plt.tight_layout()\n",
    "            fig.savefig(filestr+\"/saved_figs/\"+f\"worm{w}_pca.png\")\n",
    "            plt.close()\n",
    "    return q_x_full\n",
    "\n",
    "def variance_explained(y_pred, y_true):\n",
    "    sse = np.sum((y_true - y_pred) ** 2)\n",
    "    sst = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - sse / sst\n",
    "\n",
    "def plot_var_explained(worm_models, q_x_full, filestr):\n",
    "\n",
    "    q_y = []\n",
    "    y_hat = []\n",
    "    for w, model in enumerate(worm_models): \n",
    "        y_hat.append(Y[w])\n",
    "        q_y.append(model.smooth(q_x_full[w],Y[w]))\n",
    "    var_explained = variance_explained(np.concatenate(q_y).flatten()[np.concatenate(masks).flatten()==1],\n",
    "                                    np.concatenate(y_hat).flatten()[np.concatenate(masks).flatten()==1])\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(16,6))\n",
    "\n",
    "    neurons = np.zeros((neural_labels.size, len(q_y))) + np.nan\n",
    "    for w in range(len(q_y)):\n",
    "        for neuron in range(worm_models[0].N):\n",
    "            if sum(Y[w][:,neuron]) !=0:\n",
    "                neurons[neuron, w] = variance_explained(q_y[w][:,neuron], Y[w][:,neuron])\n",
    "    sns.boxplot(neurons.T, ax=ax)\n",
    "    np.save(filestr+\"/neural_var_explained.npy\", neurons)\n",
    "    ax.set_xticks(np.arange(neural_labels.size), neural_labels, rotation=90, fontsize=4);\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.set_title(f\"var explained:{var_explained}\")\n",
    "    fig.savefig(filestr+\"/saved_figs/\"+\"var_explained.pdf\")\n",
    "    plt.close()\n",
    "\n",
    "    return var_explained\n",
    "\n",
    "def train_model(n_disc_states, n_latent_dim, filestr):\n",
    "    slds, q = train_global_rslds(n_disc_states, n_latent_dim)\n",
    "\n",
    "    with open(filestr+\"/saved_data/prior.npy\", 'wb') as handle:\n",
    "        pickle.dump(slds, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(filestr+\"/saved_data/prior_q.npy\", 'wb') as handle:   \n",
    "        pickle.dump(q, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    global_prior, worm_models = initialize_worm_models(slds)\n",
    "\n",
    "    # train each model\n",
    "    \n",
    "    for step in range(1):\n",
    "            global_prior = update_global_prior(worm_models, global_prior)\n",
    "            for model in worm_models:\n",
    "                resample_parameters(model, global_prior)\n",
    "            qs = []\n",
    "            for worm, model in tqdm(enumerate(worm_models)):\n",
    "                q_elbos, q_worm = model.fit(Y[worm], method=\"laplace_em\", #default\n",
    "                                        variational_posterior=\"structured_meanfield\", #default\n",
    "                                        num_iters=50, alpha=0, masks=[masks[worm]], initialize=False, verbose=False)\n",
    "                qs.append(q_worm)\n",
    "            global_prior = update_global_prior(worm_models, global_prior)\n",
    "\n",
    "    with open(filestr+\"/saved_data/worm_models.npy\", 'wb') as handle:\n",
    "        pickle.dump(worm_models, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    with open(filestr+\"/saved_data/q_data.npy\", 'wb') as handle:\n",
    "        pickle.dump(qs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            \n",
    "\n",
    "    return slds, qs, global_prior, worm_models\n",
    "\n",
    "\n",
    "\n",
    "def input_slds(slds, input_list_dynamics, input_list_emissions=[]):\n",
    "    new_slds = copy.deepcopy(slds)\n",
    "\n",
    "    new_slds.M += len(input_list_dynamics) + len(input_list_emissions)\n",
    "    new_slds.emissions.M = new_slds.M\n",
    "    new_slds.dynamics.M = new_slds.M\n",
    "    new_slds.transitions.M = new_slds.M\n",
    "\n",
    "    # Inititalize new input-driven properties\n",
    "    Vs = np.zeros((new_slds.K, new_slds.D, new_slds.M))\n",
    "    Fs = np.zeros((1, new_slds.N, new_slds.M))\n",
    "    Ws = np.zeros((new_slds.K, new_slds.M))\n",
    "\n",
    "    if slds.M > 0: #if old slds already supported inputs\n",
    "        Vs[:,:,:slds.M] = slds.dynamics.Vs\n",
    "        Ws[:,:slds.M] = slds.transitions.Ws\n",
    "        Fs[:,:,:slds.M] = slds.emissions.Fs\n",
    "\n",
    "    # Here I'm only changing Vs but maybe its worth changing Ws at some point\n",
    "    input_dict = {} # neuron name -> input index\n",
    "    for i in range(len(input_list_dynamics)):\n",
    "        input_dict[input_list_dynamics[i]] = slds.M+i\n",
    "        idx = np.argwhere(neural_labels == f\"dF - {input_list_dynamics[i]}\")[0][0]\n",
    "        latent_vec = new_slds.emissions.Cs[0][idx]\n",
    "        for k in range(new_slds.K):\n",
    "            Vs[k, :,slds.M+i] = latent_vec\n",
    "\n",
    "    for i in range(len(input_list_emissions)):\n",
    "        input_dict[\"e\"+input_list_emissions[i]] = slds.M + i + len(input_list_dynamics)\n",
    "   \n",
    "        idx = np.argwhere(neural_labels == f\"dF - {input_list_emissions[i]}\")[0][0]\n",
    "        Fs[0,idx,slds.M+i+ len(input_list_dynamics)] = 10\n",
    "        idx = np.argwhere(neural_labels == f\"F - {input_list_emissions[i]}\")[0][0]\n",
    "        Fs[0,idx,slds.M+i+ len(input_list_dynamics)] = 10\n",
    "                \n",
    "    new_slds.dynamics.Vs = Vs\n",
    "    new_slds.transitions.Ws = Ws\n",
    "    new_slds.emissions.Fs = Fs\n",
    "    return new_slds, input_dict\n",
    "\n",
    "\n",
    "def inhibit_rim(slds, q_x, filestr, tag):\n",
    "    input_list = [\"RIM\"]\n",
    "    try:\n",
    "        new_slds, input_dict = input_slds(slds, input_list, input_list)\n",
    "    except:\n",
    "        print(\"error: you threw away RIM\")\n",
    "        return\n",
    "\n",
    "    new_slds.D = int(new_slds.D)\n",
    "\n",
    "    T=1000\n",
    "    pca_x = q_x\n",
    "    inputs = np.zeros((T,new_slds.M))\n",
    "    input_id = input_dict[\"RIM\"]\n",
    "    input_str = -3\n",
    "    inputs[500:,input_id] = input_str\n",
    "\n",
    "    # Create the figure and the gridspec layout\n",
    "    fig = plt.figure(figsize=(18, 8))\n",
    "    gs = gridspec.GridSpec(2, 3, height_ratios=[1, 5])  # 2 rows, 3 columns\n",
    "    ax = fig.add_subplot(gs[0, :])\n",
    "    ax.plot(inputs[:, input_id])\n",
    "    ax.set_xlabel(\"time\")\n",
    "    ax1 = fig.add_subplot(gs[1, 0])\n",
    "    ax2 = fig.add_subplot(gs[1, 1])\n",
    "    ax3 = fig.add_subplot(gs[1, 2])\n",
    "\n",
    "\n",
    "    test_z, test_x, test_y = new_slds.sample(T=T, input=inputs, with_noise=True)\n",
    "    junk, lim = plot_most_likely_dynamics_new(new_slds, test_x, test_z, pca_x, input_id=input_id, input_str=0, ax=ax1)\n",
    "    plot_most_likely_dynamics_new(new_slds, test_x[0:500], test_z[0:500], pca_x, input_id=input_id, input_str=0, ax=ax2, lim = lim, inds=(0,1));\n",
    "    plot_most_likely_dynamics_new(new_slds, test_x[500:], test_z[500:], pca_x, input_id=input_id, input_str=input_str, ax=ax3, lim = lim, pc3=-7);\n",
    "\n",
    "    ax.set_title(\"RIM Stimulation\")\n",
    "    ax1.set_title(\"full trajectory\")\n",
    "    ax2.set_title(\"pre-stim trajectory\")\n",
    "    ax3.set_title(\"post-stim trajectory\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(filestr + \"/saved_figs/RIM_\"+tag+\".png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 4, D = 4\n",
      "overlap [[407.  38.  98.  37.]\n",
      " [  9. 377.   8. 203.]\n",
      " [159.  57. 159.  47.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [05:05, 14.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap [[349.  52. 175.   4.]\n",
      " [ 13. 527.   6.  51.]\n",
      " [216.  98.  68.  40.]]\n",
      "overlap [[349.  52. 175.   4.]\n",
      " [ 13. 527.   6.  51.]\n",
      " [216.  98.  68.  40.]]\n",
      "overlap [[940.  73.  27.  80.]\n",
      " [ 22.   8. 184. 187.]\n",
      " [ 11.  25.  42.   0.]]\n",
      "overlap [[940.  80.  27.  73.]\n",
      " [ 22. 187. 184.   8.]\n",
      " [ 11.   0.  42.  25.]]\n",
      "overlap [[ 11.  99. 220. 362.]\n",
      " [387.  72.  43. 242.]\n",
      " [ 63.   2.  83.  15.]]\n",
      "overlap [[362.  11. 220.  99.]\n",
      " [242. 387.  43.  72.]\n",
      " [ 16.  62.  83.   2.]]\n",
      "overlap [[279.  21. 342. 201.]\n",
      " [104. 301. 109.  86.]\n",
      " [ 34.   4. 118.   0.]]\n",
      "overlap [[279.  21. 342. 201.]\n",
      " [104. 301. 109.  86.]\n",
      " [ 34.   4. 118.   0.]]\n",
      "overlap [[197.  77. 463.  23.]\n",
      " [ 86.  84.  12. 441.]\n",
      " [ 37.  16. 138.  25.]]\n",
      "overlap [[464.  23. 196.  77.]\n",
      " [ 12. 441.  86.  84.]\n",
      " [138.  25.  37.  16.]]\n",
      "overlap [[161.  19. 503. 100.]\n",
      " [285. 273.   4.  88.]\n",
      " [  6.  34.  76.  50.]]\n",
      "overlap [[503. 161. 100.  19.]\n",
      " [  5. 284.  88. 273.]\n",
      " [ 76.   6.  50.  34.]]\n",
      "overlap [[554.   9.  59. 270.]\n",
      " [ 64.  51. 313.  25.]\n",
      " [ 75. 133.  20.  26.]]\n",
      "overlap [[554.  59.   9. 270.]\n",
      " [ 64. 313.  51.  25.]\n",
      " [ 75.  20. 133.  26.]]\n",
      "overlap [[ 46.  74.  69. 453.]\n",
      " [272.  25.  85. 189.]\n",
      " [ 32. 176. 122.  56.]]\n",
      "overlap [[453.  46.  74.  69.]\n",
      " [189. 272.  25.  85.]\n",
      " [ 57.  31. 176. 122.]]\n",
      "overlap [[651.  39.  48.  94.]\n",
      " [ 10. 268.  13. 321.]\n",
      " [ 62.  50.  43.   0.]]\n",
      "overlap [[651.  94.  39.  48.]\n",
      " [ 10. 321. 268.  13.]\n",
      " [ 62.   0.  50.  43.]]\n",
      "overlap [[414.  19.  77. 102.]\n",
      " [  9.   9. 298. 124.]\n",
      " [252. 145.  69.  81.]]\n",
      "overlap [[414.  77.  19. 102.]\n",
      " [  9. 298.   9. 124.]\n",
      " [252.  69. 145.  81.]]\n",
      "overlap [[519.  66. 178.  60.]\n",
      " [105. 104.  16. 482.]\n",
      " [ 13.  22.  17.  17.]]\n",
      "overlap [[519.  60.  66. 178.]\n",
      " [105. 482. 104.  16.]\n",
      " [ 13.  17.  22.  17.]]\n",
      "overlap [[523.  75. 125.  74.]\n",
      " [ 17. 323.  10. 258.]\n",
      " [ 31.  30. 115.  18.]]\n",
      "overlap [[523.  75. 125.  74.]\n",
      " [ 17. 323.  10. 258.]\n",
      " [ 31.  30. 115.  18.]]\n",
      "overlap [[518. 101.  83.   1.]\n",
      " [ 92. 170.  64. 346.]\n",
      " [ 45.   6. 155.  18.]]\n",
      "overlap [[518.   1.  83. 101.]\n",
      " [ 92. 346.  64. 170.]\n",
      " [ 45.  18. 155.   6.]]\n",
      "overlap [[ 53.  16. 273. 532.]\n",
      " [184. 291.  70.  16.]\n",
      " [  0.   9.   0. 155.]]\n",
      "overlap [[532.  16. 273.  53.]\n",
      " [ 17. 291.  70. 183.]\n",
      " [155.   9.   0.   0.]]\n",
      "overlap [[227. 515. 152.  18.]\n",
      " [256.   7.  10. 320.]\n",
      " [  5.  63.  21.   5.]]\n",
      "overlap [[516.  18. 152. 226.]\n",
      " [  7. 320.  10. 256.]\n",
      " [ 63.   5.  21.   5.]]\n",
      "overlap [[470. 224.  32.  93.]\n",
      " [  0.   4. 136. 368.]\n",
      " [ 89.  70. 108.   5.]]\n",
      "overlap [[470.  93.  32. 224.]\n",
      " [  0. 368. 136.   4.]\n",
      " [ 89.   5. 108.  70.]]\n",
      "overlap [[425.  79.  95.   0.]\n",
      " [  1. 128.  66. 346.]\n",
      " [285.  61.  78.  35.]]\n",
      "overlap [[425.   0.  95.  79.]\n",
      " [  1. 346.  66. 128.]\n",
      " [285.  35.  78.  61.]]\n",
      "overlap [[586.  25.  92. 115.]\n",
      " [ 31. 339.  17. 200.]\n",
      " [ 81.  11.  85.  17.]]\n",
      "overlap [[586.  25.  92. 115.]\n",
      " [ 31. 339.  17. 200.]\n",
      " [ 81.  11.  85.  17.]]\n",
      "overlap [[599.   9.  44. 140.]\n",
      " [ 32. 585.  46.  98.]\n",
      " [ 18.   9.  19.   0.]]\n",
      "overlap [[599.   9.  44. 140.]\n",
      " [ 32. 585.  46.  98.]\n",
      " [ 18.   9.  19.   0.]]\n",
      "overlap [[125.  51. 274. 100.]\n",
      " [ 12. 250.  63. 185.]\n",
      " [219.  57.  98. 165.]]\n",
      "overlap [[274.  51. 125. 100.]\n",
      " [ 64. 250.  11. 185.]\n",
      " [ 98.  57. 219. 165.]]\n",
      "overlap [[332.  66. 404.  63.]\n",
      " [  8. 140.  50. 348.]\n",
      " [ 84.  84.  18.   2.]]\n",
      "overlap [[405.  63. 331.  66.]\n",
      " [ 50. 348.   8. 140.]\n",
      " [ 18.   2.  84.  84.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/friederikebuck/miniconda3/envs/DLC_YOLO_GUI/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 4, D = 5\n",
      "overlap [[181.  48. 342.   9.]\n",
      " [  5. 440. 137.  15.]\n",
      " [228.  68.  93.  33.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [05:34, 15.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap [[  7. 465.  31.  77.]\n",
      " [  7.   5.  64. 521.]\n",
      " [189. 105.  83.  45.]]\n",
      "overlap [[465.  77.   7.  31.]\n",
      " [  6. 521.   6.  64.]\n",
      " [105.  45. 189.  83.]]\n",
      "overlap [[ 30.  56. 194. 840.]\n",
      " [ 79. 188.  15. 119.]\n",
      " [ 20.   0.  40.  18.]]\n",
      "overlap [[841.  56. 194.  29.]\n",
      " [119. 188.  15.  79.]\n",
      " [ 18.   0.  40.  20.]]\n",
      "overlap [[329.   6. 250. 107.]\n",
      " [200. 451.  22.  71.]\n",
      " [ 11.  51.  38.  63.]]\n",
      "overlap [[329.   6. 107. 250.]\n",
      " [200. 451.  71.  22.]\n",
      " [ 11.  51.  63.  38.]]\n",
      "overlap [[113. 444. 266.  20.]\n",
      " [ 88. 114.  31. 367.]\n",
      " [ 38.  21.  73.  24.]]\n",
      "overlap [[445.  20. 266. 112.]\n",
      " [114. 367.  31.  88.]\n",
      " [ 21.  24.  73.  38.]]\n",
      "overlap [[ 96.  71. 350. 243.]\n",
      " [399.  31.  19. 174.]\n",
      " [ 21.   8. 121.  66.]]\n",
      "overlap [[351.  95. 243.  71.]\n",
      " [ 19. 399. 174.  31.]\n",
      " [121.  21.  66.   8.]]\n",
      "overlap [[428. 160. 154.  41.]\n",
      " [317. 126.  10. 197.]\n",
      " [  6.  91.  35.  34.]]\n",
      "overlap [[428.  41. 160. 154.]\n",
      " [317. 197. 126.  10.]\n",
      " [  6.  34.  91.  35.]]\n",
      "overlap [[159.  20. 686.  27.]\n",
      " [256. 138.  41.  18.]\n",
      " [ 62.  47.  41. 104.]]\n",
      "overlap [[686. 159.  27.  20.]\n",
      " [ 41. 256.  18. 138.]\n",
      " [ 42.  61. 104.  47.]]\n",
      "overlap [[451.  99.  51.  41.]\n",
      " [ 11.  45. 208. 307.]\n",
      " [106. 204.  37.  39.]]\n",
      "overlap [[451.  41.  99.  51.]\n",
      " [ 11. 307.  45. 208.]\n",
      " [106.  39. 204.  37.]]\n",
      "overlap [[579.  32. 182.  39.]\n",
      " [ 10. 117.  47. 438.]\n",
      " [ 12.  56.  86.   1.]]\n",
      "overlap [[579.  39. 182.  32.]\n",
      " [ 10. 438.  47. 117.]\n",
      " [ 12.   1.  86.  56.]]\n",
      "overlap [[176.   4. 391.  41.]\n",
      " [354.  47.  17.  22.]\n",
      " [ 57. 104. 331.  55.]]\n",
      "overlap [[392. 175.   4.  41.]\n",
      " [ 17. 354.  47.  22.]\n",
      " [331.  57. 104.  55.]]\n",
      "overlap [[274. 157. 347.  45.]\n",
      " [143. 365.   6. 193.]\n",
      " [ 14.   7.  32.  16.]]\n",
      "overlap [[347. 157.  45. 274.]\n",
      " [  7. 365. 193. 142.]\n",
      " [ 32.   7.  16.  14.]]\n",
      "overlap [[396.  82. 164. 155.]\n",
      " [ 50. 474.  70.  14.]\n",
      " [ 96.   8.  10.  80.]]\n",
      "overlap [[396.  82. 155. 164.]\n",
      " [ 50. 474.  14.  70.]\n",
      " [ 96.   8.  80.  10.]]\n",
      "overlap [[391.  38. 263.  11.]\n",
      " [153. 364.  11. 144.]\n",
      " [ 12.  28. 148.  36.]]\n",
      "overlap [[391.  38. 263.  11.]\n",
      " [153. 364.  11. 144.]\n",
      " [ 12.  28. 148.  36.]]\n",
      "overlap [[138. 119. 600.  17.]\n",
      " [ 16. 258.  17. 270.]\n",
      " [ 78.   0.  82.   4.]]\n",
      "overlap [[600.  17. 138. 119.]\n",
      " [ 18. 270.  15. 258.]\n",
      " [ 82.   4.  78.   0.]]\n",
      "overlap [[444.  17. 448.   3.]\n",
      " [ 14. 150.  59. 370.]\n",
      " [ 70.   7.  15.   2.]]\n",
      "overlap [[449.   3. 443.  17.]\n",
      " [ 59. 370.  14. 150.]\n",
      " [ 15.   2.  70.   7.]]\n",
      "overlap [[510.  39. 244.  26.]\n",
      " [142.  27.   3. 336.]\n",
      " [  0.  21. 137. 114.]]\n",
      "overlap [[510.  26. 244.  39.]\n",
      " [142. 336.   3.  27.]\n",
      " [  0. 114. 137.  21.]]\n",
      "overlap [[ 91.  29.  22. 457.]\n",
      " [145. 386.   0.  10.]\n",
      " [106.  39. 186. 128.]]\n",
      "overlap [[458.  29.  22.  90.]\n",
      " [ 10. 386.   0. 145.]\n",
      " [128.  39. 186. 106.]]\n",
      "overlap [[ 98. 102. 514. 104.]\n",
      " [ 84. 431.  27.  45.]\n",
      " [ 42.  27.  89.  36.]]\n",
      "overlap [[514. 102.  98. 104.]\n",
      " [ 28. 431.  83.  45.]\n",
      " [ 89.  27.  42.  36.]]\n",
      "overlap [[514.  74. 177.  27.]\n",
      " [ 15. 124.  32. 590.]\n",
      " [  3.   8.  26.   9.]]\n",
      "overlap [[514.  27. 177.  74.]\n",
      " [ 15. 590.  32. 124.]\n",
      " [  3.   9.  26.   8.]]\n",
      "overlap [[176. 125. 229.  20.]\n",
      " [115.  90.   8. 297.]\n",
      " [ 65. 141. 236.  97.]]\n",
      "overlap [[176.  20. 229. 125.]\n",
      " [115. 297.   8.  90.]\n",
      " [ 65.  97. 236. 141.]]\n",
      "overlap [[ 10.  82. 503. 270.]\n",
      " [419.  77.  40.  10.]\n",
      " [  9.  78.  37.  64.]]\n",
      "overlap [[504.   9.  82. 270.]\n",
      " [ 40. 419.  77.  10.]\n",
      " [ 37.   9.  78.  64.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/friederikebuck/miniconda3/envs/DLC_YOLO_GUI/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 4, D = 6\n",
      "overlap [[ 10.  10. 441. 119.]\n",
      " [103. 416.  28.  50.]\n",
      " [ 42.  39. 200. 141.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [06:08, 17.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap [[382.  24.  96.  78.]\n",
      " [  4. 198.   9. 386.]\n",
      " [243.  24.  61.  94.]]\n",
      "overlap [[382.  78.  96.  24.]\n",
      " [  4. 386.   9. 198.]\n",
      " [243.  94.  61.  24.]]\n",
      "overlap [[151.  92. 847.  30.]\n",
      " [ 10. 209.  20. 162.]\n",
      " [ 17.   3.  27.  31.]]\n",
      "overlap [[848.  92.  30. 150.]\n",
      " [ 20. 209. 162.  10.]\n",
      " [ 27.   3.  31.  17.]]\n",
      "overlap [[185.  72. 410.  25.]\n",
      " [107. 218.  43. 376.]\n",
      " [111.  14.   3.  35.]]\n",
      "overlap [[410.  25. 185.  72.]\n",
      " [ 43. 376. 107. 218.]\n",
      " [  4.  35. 110.  14.]]\n",
      "overlap [[348. 408.  25.  62.]\n",
      " [ 10.  95. 422.  73.]\n",
      " [109.  18.  10.  19.]]\n",
      "overlap [[409.  25. 347.  62.]\n",
      " [ 95. 422.  10.  73.]\n",
      " [ 18.  10. 109.  19.]]\n",
      "overlap [[261.  84. 284. 131.]\n",
      " [145. 415.  12.  51.]\n",
      " [ 71.  28. 110.   7.]]\n",
      "overlap [[261.  84. 284. 131.]\n",
      " [145. 415.  12.  51.]\n",
      " [ 71.  28. 110.   7.]]\n",
      "overlap [[458. 122. 138.  65.]\n",
      " [159. 143. 107. 241.]\n",
      " [  5.  37.  88.  36.]]\n",
      "overlap [[458.  65. 138. 122.]\n",
      " [159. 241. 107. 143.]\n",
      " [  5.  36.  88.  37.]]\n",
      "overlap [[137.  99. 645.  11.]\n",
      " [ 16. 200.  85. 152.]\n",
      " [ 91.  82.  46.  35.]]\n",
      "overlap [[645.  99. 137.  11.]\n",
      " [ 85. 200.  16. 152.]\n",
      " [ 47.  82.  90.  35.]]\n",
      "overlap [[453.  93.  56.  40.]\n",
      " [ 15.  60. 105. 391.]\n",
      " [ 84. 189.  63.  50.]]\n",
      "overlap [[453.  40.  93.  56.]\n",
      " [ 15. 391.  60. 105.]\n",
      " [ 84.  50. 189.  63.]]\n",
      "overlap [[621.  44. 120.  47.]\n",
      " [ 20. 485.  64.  43.]\n",
      " [ 20.   9.  46.  80.]]\n",
      "overlap [[621.  44.  47. 120.]\n",
      " [ 20. 485.  43.  64.]\n",
      " [ 20.   9.  80.  46.]]\n",
      "overlap [[146.  67. 375.  24.]\n",
      " [ 34. 368.   3.  35.]\n",
      " [140.  87. 222.  98.]]\n",
      "overlap [[376.  67. 145.  24.]\n",
      " [  3. 368.  34.  35.]\n",
      " [222.  87. 140.  98.]]\n",
      "overlap [[474.  60. 171. 118.]\n",
      " [ 32. 478.  92. 105.]\n",
      " [ 16.  18.  35.   0.]]\n",
      "overlap [[474.  60. 171. 118.]\n",
      " [ 32. 478.  92. 105.]\n",
      " [ 16.  18.  35.   0.]]\n",
      "overlap [[516.  97. 179.   5.]\n",
      " [ 67. 312.  91. 138.]\n",
      " [ 84.  19.  46.  45.]]\n",
      "overlap [[516.  97. 179.   5.]\n",
      " [ 67. 312.  91. 138.]\n",
      " [ 84.  19.  46.  45.]]\n",
      "overlap [[472.  26. 101. 104.]\n",
      " [ 31. 164.  86. 391.]\n",
      " [115.  54.  41.  14.]]\n",
      "overlap [[472. 104.  26. 101.]\n",
      " [ 31. 391. 164.  86.]\n",
      " [115.  14.  54.  41.]]\n",
      "overlap [[399.   9. 343. 123.]\n",
      " [122. 321.   0. 118.]\n",
      " [  2.   3. 136.  23.]]\n",
      "overlap [[399.   9. 343. 123.]\n",
      " [122. 321.   0. 118.]\n",
      " [  2.   3. 136.  23.]]\n",
      "overlap [[393.  52. 192. 275.]\n",
      " [  8. 344. 227.  14.]\n",
      " [ 52.   3.  13.  26.]]\n",
      "overlap [[393.  52. 275. 192.]\n",
      " [  8. 344.  14. 227.]\n",
      " [ 52.   3.  26.  13.]]\n",
      "overlap [[ 83.  52. 503. 181.]\n",
      " [ 11.  77.  52. 368.]\n",
      " [ 62. 148.  49.  13.]]\n",
      "overlap [[504. 181.  52.  82.]\n",
      " [ 52. 368.  77.  11.]\n",
      " [ 49.  13. 148.  62.]]\n",
      "overlap [[ 11.   7. 178. 403.]\n",
      " [  0. 373.  76.  92.]\n",
      " [142.  30.  82. 205.]]\n",
      "overlap [[404.   7.  10. 178.]\n",
      " [ 92. 373.   0.  76.]\n",
      " [205.  30. 142.  82.]]\n",
      "overlap [[478. 106. 214.  20.]\n",
      " [ 23. 255.   7. 302.]\n",
      " [ 34.   5. 124.  31.]]\n",
      "overlap [[478.  20. 214. 106.]\n",
      " [ 23. 302.   7. 255.]\n",
      " [ 34.  31. 124.   5.]]\n",
      "overlap [[131.   4. 455. 202.]\n",
      " [ 36. 528.  60. 137.]\n",
      " [ 22.   8.  14.   2.]]\n",
      "overlap [[455.   4. 131. 202.]\n",
      " [ 61. 528.  35. 137.]\n",
      " [ 14.   8.  22.   2.]]\n",
      "overlap [[ 81.  43. 205. 221.]\n",
      " [ 60. 184. 258.   8.]\n",
      " [ 60. 102. 141. 236.]]\n",
      "overlap [[205.  43. 221.  81.]\n",
      " [259. 184.   8.  59.]\n",
      " [141. 102. 236.  60.]]\n",
      "overlap [[471.  13.  70. 311.]\n",
      " [ 81. 428.  31.   6.]\n",
      " [ 45.   5.  87.  51.]]\n",
      "overlap [[471.  13.  70. 311.]\n",
      " [ 81. 428.  31.   6.]\n",
      " [ 45.   5.  87.  51.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/friederikebuck/miniconda3/envs/DLC_YOLO_GUI/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "formatted_datetime = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "os.mkdir(formatted_datetime)\n",
    "np.save(formatted_datetime+\"/neurons.npy\", neural_labels)\n",
    "with open(formatted_datetime+\"/Y.npy\", 'wb') as handle:\n",
    "        pickle.dump(Y, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Ds = np.arange(3,7,1)\n",
    "Ds = np.arange(4,7,1)\n",
    "# Ks = np.arange(3,4,1)\n",
    "Ks = np.arange(4,5,1)\n",
    "fitting_results = np.zeros((Ds.size,Ks.size))\n",
    "\n",
    "i=0\n",
    "for n_disc_states in Ks:\n",
    "    j=0\n",
    "    for latent_dim in Ds:\n",
    "        print(f\"K = {n_disc_states}, D = {latent_dim}\")\n",
    "        filestr = formatted_datetime+f\"/N{emissions_dim}_D{latent_dim}_K{n_disc_states}\"\n",
    "\n",
    "        os.mkdir(filestr)\n",
    "        os.mkdir(filestr+\"/saved_data\")\n",
    "        os.mkdir(filestr+\"/saved_figs\")\n",
    "\n",
    "\n",
    "        slds, qs, global_prior, worm_models = train_model(n_disc_states, latent_dim, filestr)\n",
    "        q_x_full = plot_and_save(worm_models, qs, filestr)\n",
    "        inhibit_rim(slds, q_x_full[11], filestr, \"\")\n",
    "        var_explained = plot_var_explained(worm_models, q_x_full, filestr)\n",
    "        fitting_results[j][i] = var_explained\n",
    "        j+=1\n",
    "    \n",
    "    fig,ax = plt.subplots()\n",
    "    ax.plot(Ds, fitting_results[:,i])\n",
    "    ax.set_xlabel(\"# latent dims\")\n",
    "    ax.set_ylabel(\"var explained\")\n",
    "    ax.set_ylim(0,1)\n",
    "    fig.savefig(formatted_datetime+f\"/K{n_disc_states}.png\")\n",
    "    plt.close()\n",
    "    i+=1\n",
    "np.save(formatted_datetime+\"/var_explained.npy\",fitting_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_x_full = plot_and_save(worm_models, qs, filestr)\n",
    "inhibit_rim(slds, q_x_full[11], filestr, \"\")\n",
    "var_explained = plot_var_explained(worm_models, q_x_full, filestr)\n",
    "fitting_results[j][i] = var_explained\n",
    "j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refit the same thing over and over to get a sense of the variance of solutons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_plot(n_disc_states, latent_dim, filestr, tag):\n",
    "    # Train model\n",
    "    slds, q = train_global_rslds(n_disc_states, latent_dim)\n",
    "\n",
    "    # Save data\n",
    "    with open(filestr+\"/saved_data/prior.npy\", 'wb') as handle:\n",
    "        pickle.dump(slds, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(filestr+\"/saved_data/prior_q.npy\", 'wb') as handle:   \n",
    "        pickle.dump(q, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # plot worm 11\n",
    "    q_x = q.mean_continuous_states[11]\n",
    "    q_z = slds.most_likely_states(q_x, Y[11])\n",
    "    ax, lim = plot_most_likely_dynamics_new(slds, q_x[0:300], q_z[0:300], q_x, inds=(0,1), do_pca=True)\n",
    "    q_x = q.mean_continuous_states\n",
    "    ax.set_title(f\"worm 11 (global)\")\n",
    "    plt.savefig(filestr+\"/saved_figs/worm11_\" + tag+ \".png\")\n",
    "    plt.close()\n",
    "    return slds, q_x, q_z\n",
    "\n",
    "\n",
    "def inhibit_rim(slds, q_x, filestr, tag):\n",
    "    input_list = [\"AVA\", \"RIB\", \"RIM\", \"AIB\"]\n",
    "    new_slds, input_dict = input_slds(slds, input_list, input_list)\n",
    "    new_slds.D = int(new_slds.D)\n",
    "\n",
    "    T=1000\n",
    "    pca_x = q_x\n",
    "    inputs = np.zeros((T,new_slds.M))\n",
    "    input_id = input_dict[\"RIM\"]\n",
    "    input_str = -3\n",
    "    inputs[500:,input_id] = input_str\n",
    "\n",
    "    # Create the figure and the gridspec layout\n",
    "    fig = plt.figure(figsize=(18, 8))\n",
    "    gs = gridspec.GridSpec(2, 3, height_ratios=[1, 5])  # 2 rows, 3 columns\n",
    "    ax = fig.add_subplot(gs[0, :])\n",
    "    ax.plot(inputs[:, input_id])\n",
    "    ax.set_xlabel(\"time\")\n",
    "    ax1 = fig.add_subplot(gs[1, 0])\n",
    "    ax2 = fig.add_subplot(gs[1, 1])\n",
    "    ax3 = fig.add_subplot(gs[1, 2])\n",
    "\n",
    "\n",
    "    test_z, test_x, test_y = new_slds.sample(T=T, input=inputs, with_noise=True)\n",
    "    junk, lim = plot_most_likely_dynamics_new(new_slds, test_x, test_z, pca_x, input_id=input_id, input_str=0, ax=ax1)\n",
    "    plot_most_likely_dynamics_new(new_slds, test_x[0:500], test_z[0:500], pca_x, input_id=input_id, input_str=0, ax=ax2, lim = lim, inds=(0,1));\n",
    "    plot_most_likely_dynamics_new(new_slds, test_x[500:], test_z[500:], pca_x, input_id=input_id, input_str=input_str, ax=ax3, lim = lim, pc3=-7);\n",
    "\n",
    "    ax.set_title(\"RIM Stimulation\")\n",
    "    ax1.set_title(\"full trajectory\")\n",
    "    ax2.set_title(\"pre-stim trajectory\")\n",
    "    ax3.set_title(\"post-stim trajectory\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(filestr + \"/saved_figs/RIM_\"+tag+\".png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_var_explained_prior(slds, q_x_full, filestr, tag):\n",
    "\n",
    "    q_y = []\n",
    "    y_hat = []\n",
    "    for w in range(21): \n",
    "        y_hat.append(Y[w])\n",
    "        q_y.append(slds.smooth(q_x_full[w],Y[w]))\n",
    "    var_explained = variance_explained(np.concatenate(q_y).flatten()[np.concatenate(masks).flatten()==1],\n",
    "                                    np.concatenate(y_hat).flatten()[np.concatenate(masks).flatten()==1])\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(16,6))\n",
    "\n",
    "    neurons = np.zeros((neural_labels.size, len(q_y))) + np.nan\n",
    "    for w in range(len(q_y)):\n",
    "        for neuron in range(slds.N):\n",
    "            if sum(Y[w][:,neuron]) !=0:\n",
    "                neurons[neuron, w] = variance_explained(q_y[w][:,neuron], Y[w][:,neuron])\n",
    "    sns.boxplot(neurons.T, ax=ax)\n",
    "    np.save(filestr+\"/neural_var_explained.npy\", neurons)\n",
    "    ax.set_xticks(np.arange(neural_labels.size), neural_labels, rotation=90, fontsize=8);\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.set_title(f\"var explained:{var_explained}\")\n",
    "    fig.savefig(filestr+\"/saved_figs/\"+\"var_explained_\"+tag+\".pdf\")\n",
    "    plt.close()\n",
    "\n",
    "    return var_explained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 3, D = 2\n",
      "K = 3, D = 3\n",
      "K = 3, D = 4\n",
      "K = 3, D = 5\n",
      "K = 3, D = 6\n",
      "K = 3, D = 7\n",
      "K = 3, D = 8\n",
      "K = 3, D = 9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(filestr\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/saved_figs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 22\u001b[0m slds, q_x, q_z \u001b[38;5;241m=\u001b[39m train_and_plot(n_disc_states, latent_dim, filestr, tag)\n\u001b[1;32m     23\u001b[0m inhibit_rim(slds, q_x[\u001b[38;5;241m11\u001b[39m], filestr, tag)\n\u001b[1;32m     24\u001b[0m plot_var_explained_prior(slds, q_x, filestr, tag)\n",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m, in \u001b[0;36mtrain_and_plot\u001b[0;34m(n_disc_states, latent_dim, filestr, tag)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_and_plot\u001b[39m(n_disc_states, latent_dim, filestr, tag):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     slds, q \u001b[38;5;241m=\u001b[39m train_global_rslds(n_disc_states, latent_dim)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Save data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filestr\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/saved_data/prior.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n",
      "Cell \u001b[0;32mIn[36], line 44\u001b[0m, in \u001b[0;36mtrain_global_rslds\u001b[0;34m(n_disc_states, latent_dim, i_want_to_plot_fitting)\u001b[0m\n\u001b[1;32m     36\u001b[0m slds \u001b[38;5;241m=\u001b[39m ssm\u001b[38;5;241m.\u001b[39mSLDS(emissions_dim, n_disc_states, latent_dim,\n\u001b[1;32m     37\u001b[0m                 transitions\u001b[38;5;241m=\u001b[39mtransition,\n\u001b[1;32m     38\u001b[0m                 dynamics\u001b[38;5;241m=\u001b[39mdynamic, \n\u001b[1;32m     39\u001b[0m                 emissions\u001b[38;5;241m=\u001b[39memission, dynamics_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(l2_penalty_A\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m),\n\u001b[1;32m     40\u001b[0m                 single_subspace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Fit the model using Laplace-EM with a structured variational posterior\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m q_elbos, q \u001b[38;5;241m=\u001b[39m slds\u001b[38;5;241m.\u001b[39mfit(Y, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlaplace_em\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m#default\u001b[39;00m\n\u001b[1;32m     45\u001b[0m                             variational_posterior\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstructured_meanfield\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m#default\u001b[39;00m\n\u001b[1;32m     46\u001b[0m                             num_iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, masks\u001b[38;5;241m=\u001b[39mmasks, tags\u001b[38;5;241m=\u001b[39mtags, num_init_restarts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     slds\u001b[38;5;241m.\u001b[39mpermute(find_permutation(z[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1599\u001b[39m], slds\u001b[38;5;241m.\u001b[39mmost_likely_states(q\u001b[38;5;241m.\u001b[39mmean_continuous_states[\u001b[38;5;241m0\u001b[39m], Y[\u001b[38;5;241m0\u001b[39m])))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ssm/util.py:111\u001b[0m, in \u001b[0;36mensure_args_are_lists.<locals>.wrapper\u001b[0;34m(self, datas, inputs, masks, tags, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tags, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    109\u001b[0m     tags \u001b[38;5;241m=\u001b[39m [tags]\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;28mself\u001b[39m, datas, inputs\u001b[38;5;241m=\u001b[39minputs, masks\u001b[38;5;241m=\u001b[39mmasks, tags\u001b[38;5;241m=\u001b[39mtags, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ssm/lds.py:788\u001b[0m, in \u001b[0;36mSLDS.fit\u001b[0;34m(self, datas, inputs, masks, tags, verbose, method, variational_posterior, variational_posterior_kwargs, initialize, discrete_state_init_method, num_init_iters, num_init_restarts, **kwargs)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Initialize the model parameters\u001b[39;00m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initialize:\n\u001b[0;32m--> 788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize(datas, inputs, masks, tags,\n\u001b[1;32m    789\u001b[0m                     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    790\u001b[0m                     discrete_state_init_method\u001b[38;5;241m=\u001b[39mdiscrete_state_init_method,\n\u001b[1;32m    791\u001b[0m                     num_init_iters\u001b[38;5;241m=\u001b[39mnum_init_iters,\n\u001b[1;32m    792\u001b[0m                     num_init_restarts\u001b[38;5;241m=\u001b[39mnum_init_restarts)\n\u001b[1;32m    794\u001b[0m \u001b[38;5;66;03m# Initialize the variational posterior\u001b[39;00m\n\u001b[1;32m    795\u001b[0m variational_posterior_kwargs \u001b[38;5;241m=\u001b[39m variational_posterior_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ssm/util.py:111\u001b[0m, in \u001b[0;36mensure_args_are_lists.<locals>.wrapper\u001b[0;34m(self, datas, inputs, masks, tags, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tags, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    109\u001b[0m     tags \u001b[38;5;241m=\u001b[39m [tags]\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;28mself\u001b[39m, datas, inputs\u001b[38;5;241m=\u001b[39minputs, masks\u001b[38;5;241m=\u001b[39mmasks, tags\u001b[38;5;241m=\u001b[39mtags, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ssm/lds.py:190\u001b[0m, in \u001b[0;36mSLDS.initialize\u001b[0;34m(self, datas, inputs, masks, tags, verbose, num_init_iters, discrete_state_init_method, num_init_restarts)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing with an ARHMM using \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m steps of EM.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(num_init_iters))\n\u001b[1;32m    185\u001b[0m arhmm \u001b[38;5;241m=\u001b[39m hmm\u001b[38;5;241m.\u001b[39mHMM(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD, M\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM,\n\u001b[1;32m    186\u001b[0m                 init_state_distn\u001b[38;5;241m=\u001b[39mcopy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_state_distn),\n\u001b[1;32m    187\u001b[0m                 transitions\u001b[38;5;241m=\u001b[39mcopy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransitions),\n\u001b[1;32m    188\u001b[0m                 observations\u001b[38;5;241m=\u001b[39mcopy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamics))\n\u001b[0;32m--> 190\u001b[0m arhmm\u001b[38;5;241m.\u001b[39mfit(xs, inputs\u001b[38;5;241m=\u001b[39minputs, masks\u001b[38;5;241m=\u001b[39mxmasks, tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m    191\u001b[0m           verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    192\u001b[0m           method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    193\u001b[0m           num_iters\u001b[38;5;241m=\u001b[39mnum_init_iters,\n\u001b[1;32m    194\u001b[0m           init_method\u001b[38;5;241m=\u001b[39mdiscrete_state_init_method)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m#Keep track of the arhmm that led to the highest log probability\u001b[39;00m\n\u001b[1;32m    197\u001b[0m current_lp \u001b[38;5;241m=\u001b[39m arhmm\u001b[38;5;241m.\u001b[39mlog_probability(xs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ssm/util.py:111\u001b[0m, in \u001b[0;36mensure_args_are_lists.<locals>.wrapper\u001b[0;34m(self, datas, inputs, masks, tags, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tags, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    109\u001b[0m     tags \u001b[38;5;241m=\u001b[39m [tags]\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;28mself\u001b[39m, datas, inputs\u001b[38;5;241m=\u001b[39minputs, masks\u001b[38;5;241m=\u001b[39mmasks, tags\u001b[38;5;241m=\u001b[39mtags, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ssm/hmm.py:504\u001b[0m, in \u001b[0;36mHMM.fit\u001b[0;34m(self, datas, inputs, masks, tags, verbose, method, initialize, init_method, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m          \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly EM is implemented for constrained transitions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# print(verbose)\u001b[39;00m\n\u001b[0;32m--> 504\u001b[0m  \u001b[38;5;28;01mreturn\u001b[39;00m _fitting_methods[method](datas,\n\u001b[1;32m    505\u001b[0m                                  inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    506\u001b[0m                                  masks\u001b[38;5;241m=\u001b[39mmasks,\n\u001b[1;32m    507\u001b[0m                                  tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m    508\u001b[0m                                  verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    509\u001b[0m                                  \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ssm/hmm.py:455\u001b[0m, in \u001b[0;36mHMM._fit_em\u001b[0;34m(self, datas, inputs, masks, tags, verbose, num_iters, tolerance, init_state_mstep_kwargs, transitions_mstep_kwargs, observations_mstep_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# M step: maximize expected log joint wrt parameters\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_state_distn\u001b[38;5;241m.\u001b[39mm_step(expectations, datas, inputs, masks, tags, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_state_mstep_kwargs)\n\u001b[0;32m--> 455\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransitions\u001b[38;5;241m.\u001b[39mm_step(expectations, datas, inputs, masks, tags, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtransitions_mstep_kwargs)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservations\u001b[38;5;241m.\u001b[39mm_step(expectations, datas, inputs, masks, tags, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mobservations_mstep_kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;66;03m# Store progress\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ssm/transitions.py:356\u001b[0m, in \u001b[0;36mRecurrentOnlyTransitions.m_step\u001b[0;34m(self, expectations, datas, inputs, masks, tags, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mm_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, expectations, datas, inputs, masks, tags, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 356\u001b[0m     Transitions\u001b[38;5;241m.\u001b[39mm_step(\u001b[38;5;28mself\u001b[39m, expectations, datas, inputs, masks, tags, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ssm/transitions.py:70\u001b[0m, in \u001b[0;36mTransitions.m_step\u001b[0;34m(self, expectations, datas, inputs, masks, tags, optimizer, num_iters, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Call the optimizer. Persist state (e.g. SGD momentum) across calls to m_step.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m optimizer_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_state \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer_state\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_state \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 70\u001b[0m     optimizer(_objective, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, num_iters\u001b[38;5;241m=\u001b[39mnum_iters,\n\u001b[1;32m     71\u001b[0m               state\u001b[38;5;241m=\u001b[39moptimizer_state, full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ssm/optimizers.py:135\u001b[0m, in \u001b[0;36m_generic_minimize\u001b[0;34m(method, loss, x0, verbose, num_iters, tol, state, full_output, suppress_warnings, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m g\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Call the optimizer.  Pass in -1 as the iteration since it is unused.\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m result \u001b[38;5;241m=\u001b[39m minimize(_objective, _x0, args\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,),\n\u001b[1;32m    136\u001b[0m                   jac\u001b[38;5;241m=\u001b[39msafe_grad,\n\u001b[1;32m    137\u001b[0m                   method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    138\u001b[0m                   callback\u001b[38;5;241m=\u001b[39mcallback \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    139\u001b[0m                   options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(maxiter\u001b[38;5;241m=\u001b[39mnum_iters, disp\u001b[38;5;241m=\u001b[39mverbose),\n\u001b[1;32m    140\u001b[0m                   tol\u001b[38;5;241m=\u001b[39mtol,\n\u001b[1;32m    141\u001b[0m                   \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m completed with message: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(method, result\u001b[38;5;241m.\u001b[39mmessage))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_minimize.py:738\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    735\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    736\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 738\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    739\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    741\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    742\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py:441\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    433\u001b[0m _lbfgsb\u001b[38;5;241m.\u001b[39msetulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[1;32m    434\u001b[0m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    444\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:344\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x(x)\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:295\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 295\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped_fun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n\u001b[1;32m    297\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:21\u001b[0m, in \u001b[0;36m_wrapper_fun.<locals>.wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     17\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ssm/optimizers.py:117\u001b[0m, in \u001b[0;36m_generic_minimize.<locals>.<lambda>\u001b[0;34m(x_flat, itr)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Flatten the loss\u001b[39;00m\n\u001b[1;32m    116\u001b[0m _x0, unflatten \u001b[38;5;241m=\u001b[39m flatten(x0)\n\u001b[0;32m--> 117\u001b[0m _objective \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x_flat, itr: loss(unflatten(x_flat), itr)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting with \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(method))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ssm/transitions.py:64\u001b[0m, in \u001b[0;36mTransitions.m_step.<locals>._objective\u001b[0;34m(params, itr)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_objective\u001b[39m(params, itr):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m params\n\u001b[0;32m---> 64\u001b[0m     obj \u001b[38;5;241m=\u001b[39m _expected_log_joint(expectations)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mobj \u001b[38;5;241m/\u001b[39m T\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ssm/transitions.py:56\u001b[0m, in \u001b[0;36mTransitions.m_step.<locals>._expected_log_joint\u001b[0;34m(expectations)\u001b[0m\n\u001b[1;32m     53\u001b[0m elbo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_prior()\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, \u001b[38;5;28minput\u001b[39m, mask, tag, (expected_states, expected_joints, _) \\\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(datas, inputs, masks, tags, expectations):\n\u001b[0;32m---> 56\u001b[0m     log_Ps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_transition_matrices(data, \u001b[38;5;28minput\u001b[39m, mask, tag)\n\u001b[1;32m     57\u001b[0m     elbo \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(expected_joints \u001b[38;5;241m*\u001b[39m log_Ps)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m elbo\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ssm/transitions.py:353\u001b[0m, in \u001b[0;36mRecurrentOnlyTransitions.log_transition_matrices\u001b[0;34m(self, data, input, mask, tag)\u001b[0m\n\u001b[1;32m    351\u001b[0m log_Ps \u001b[38;5;241m=\u001b[39m log_Ps \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr                                       \u001b[38;5;66;03m# bias\u001b[39;00m\n\u001b[1;32m    352\u001b[0m log_Ps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(log_Ps, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK, \u001b[38;5;241m1\u001b[39m))                       \u001b[38;5;66;03m# expand\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_Ps \u001b[38;5;241m-\u001b[39m logsumexp(log_Ps, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/autograd/tracer.py:48\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f_raw(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/special/_logsumexp.py:118\u001b[0m, in \u001b[0;36mlogsumexp\u001b[0;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp_size(a) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# log of zero is OK\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m         out, sgn \u001b[38;5;241m=\u001b[39m _logsumexp(a, b, axis\u001b[38;5;241m=\u001b[39maxis, return_sign\u001b[38;5;241m=\u001b[39mreturn_sign, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     shape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(a\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# NumPy is convenient for shape manipulation\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/special/_logsumexp.py:217\u001b[0m, in \u001b[0;36m_logsumexp\u001b[0;34m(a, b, axis, return_sign, xp)\u001b[0m\n\u001b[1;32m    214\u001b[0m shift \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mwhere(xp\u001b[38;5;241m.\u001b[39misfinite(a_max), a_max, xp\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39ma_max\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Shift, exponentiate, scale, and sum\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m exp \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m*\u001b[39m xp\u001b[38;5;241m.\u001b[39mexp(a \u001b[38;5;241m-\u001b[39m shift) \u001b[38;5;28;01mif\u001b[39;00m b \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mexp(a \u001b[38;5;241m-\u001b[39m shift)\n\u001b[1;32m    218\u001b[0m s \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39msum(exp, axis\u001b[38;5;241m=\u001b[39maxis, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mexp\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    219\u001b[0m s \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mwhere(s \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, s, s\u001b[38;5;241m/\u001b[39mm)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "formatted_datetime = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "os.mkdir(formatted_datetime)\n",
    "np.save(formatted_datetime+\"/neurons.npy\", neural_labels)\n",
    "with open(formatted_datetime+\"/Y.npy\", 'wb') as handle:\n",
    "        pickle.dump(Y, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "Ds = np.arange(2,10,1)\n",
    "Ks = np.arange(3,4,1)\n",
    "\n",
    "for n_disc_states in Ks:\n",
    "    for latent_dim in Ds:\n",
    "        print(f\"K = {n_disc_states}, D = {latent_dim}\")\n",
    "\n",
    "        # do it once\n",
    "        filestr = formatted_datetime+f\"/N{emissions_dim}_D{latent_dim}_K{n_disc_states}\"\n",
    "        os.mkdir(filestr)\n",
    "        os.mkdir(filestr+\"/saved_data\")\n",
    "        os.mkdir(filestr+\"/saved_figs\")\n",
    "        tags = [\"A\", \"B\", \"C\"]\n",
    "        for tag in tags:\n",
    "            slds, q_x, q_z = train_and_plot(n_disc_states, latent_dim, filestr, tag)\n",
    "            inhibit_rim(slds, q_x[11], filestr, tag)\n",
    "            plot_var_explained_prior(slds, q_x, filestr, tag)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLC_YOLO_GUI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
